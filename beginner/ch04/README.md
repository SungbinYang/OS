> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## 메모리 관리 개요

물리 메모리라는 것은 예로 512KB라는 것은 옛날에 8088XT라는 PC가 있었는데 이 PC CPU성능이 10 MHz정도 된다.

근데 상식적으로 알아야 할 내용이 뭐냐면 메모리는 총 2분류로 나눠지는데 RAM이라는 1차 메모리가 있고 SSD 혹은 HDD라는 2차 메모리가 있다. 여기서 메모리 주소 애기가 나오는데 메모리라고 하는 것에 대해서 어느 공간을 일부 잘라서 그 공간에 일련번호를 붙이는데 그 일련번호를 메모리 주소라고 한다. 또한 이 메모리 주소가 붙은 메모리의 일정한 단위 크기는 1byte이다. 즉, 1byte 메모리마다 주소가 붙는다. 근데 이 주소가 32bit 체계이면 최대크기가 2^32 = 4GB 정도가 나온다. 만약 64bit라고 하면 2^64 = 16EB 정도 나온다. 그래서 웃긴게 옛날에 32bit OS를 설치하고 RAM을 8GB를 장착하면 4GB밖에 인식을 못했는데 그 이유가 위에 설명한 이유에서 비롯된 것이다. 그러면 64bit platform에선 16EB RAM을 꽂으면 다 인식이 가능할까? 사실상 불가능하고 인식할 수 있는 RAM은 버전마다 다르지만 윈도우 홈버전 기준으로 128GB까지 인식이 되고 pro버전 이상은 2TB까지 인식이 가능하다.

## 컴파일러, 인터프리터

컴퓨터에서 연산을 하는 주체는 CPU이다. CPU가 연산을 하는 주체이긴 하지만 속도도 굉장히 빠르다. CPU에 연산할 거리들이 쭉 나열되어 있는데 CPU는 이 연산할 거리들을 끄집어내서 실행을 하려 한다. 근데 문제는 CPU는 실행하려 하는데 연산거리는 누군가 추가를 해줄 것이다. 즉, 해야할 일이 쌓여있다는 것은 CPU 연산속도가 추가하는 속도보다 더디다는 것이고 반대로 할 거리들이 비어있다는 것은 자원의 낭비가 발생한다. 이런 것들 때문에 등장하는 것이 캐시이다. 연산이 실행될때는 CPU가 인식 가능한 코드(기계어)로 바꿔야 하고 프로그램들은 일반적으로 C나 Python 등 프로그래밍 언어로 작성하는데 이 코드들을 기계어로 번역해 주는 과정이 컴파일 혹은 인터프리터라고 한다.

> 빠른 실행을 위해 이런 일거리들을 보통 RAM에 올려놓고 사용한다.

## 메모리 매니저

HDD의 정보를 RAM에 복사하고 그 RAM이 CPU에 정보를 복사하는 일련의 과정에서 개입하는 요소가 있는데 그게 메모리 매니저이다. 메모리 매니저가 하는 역할은 **가져오기, 배치, 재배치**이다. 이중에 가장 중요한 역할이 **배치정책**이다.

배치정책을 왜 애기하냐면 예를 들어 RAM이라는 공간은 한정되어 있는데 그런데 그 위에 작동하는 프로세스가 여러 개 있을 때 이 프로세스들 전부 빠른 연산을 위해 RAM을 쓰고 싶어 한다. 하지만 RAM의 기억공간은 한정적이기 때문에 이 프로세스들이 동시에 작동하기 위해서는 재배치 작업이 필요하다. 즉, RAM이 가득 찼을 때 연산을 별로 안 하는 프로세스를 HDD로 옮기고 그 자리에 다른 프로세스를 배치한다. 이때 배치를 할 때 사용하는 단위가 page이다.

> 배치정책: 가져온 프로세스를 어떤 위치에 올려놓을지 결정하는 정책  
> 페이징: 메모리를 같은 크기로 자르는 것을 말한다.  
> 세그먼테이션: 프로세스의 크기에 맞게 자르는 것을 말한다.  
> 세그먼트: 메모리를 Stack, Heap, Text, Data영역등으로 나누는데 그때 나누는 것을 말한다.

> 기본적으로 OS는 page단위로 메모리를 통제하고 윈도우 기준 page크기는 4KB이다.

> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## 절대주소와 상대주소

메모리라고 하는 것에 대해서 어느 한 단위가 있는데 크기가 1byte가 되는 것이고 이 1byte마다 메모리 주소가 붙는데 이 주소가 64bit 체계이면 64bit system, 32bit 체계이면 32bit system이라고 불린다. 근데 이것이 Application 수준에도 적용된다. 중요한 것은 RAM에는 하드웨어 수준에 부여된 주소체계가 있고 Application Process수준에 부여된 주소체계가 있는데 이 둘이 조금 다르다. 즉 이 둘의 차이가 있는데 애네 둘이 서로 다른 번호를 쓰게 되는데 왜냐하면 이 둘은 가상메모리 체계를 쓰기 때문에 이 두 주소는 일치하지 않는다. 그래서 메모리의 어떤 주소를 얘기할 때는 2가지 기준으로 간다. 절대주소와 상대주소로 가는데 쉽게 생각해서 배열을 생각하면 된다. 어떤 배열이 있으면 배열의 이름이 주소인데 이 주소를 가지고 어느 특정 메모리를 식별이 가능하다. 상대주소는 배열의 인덱스 연산(인덱싱)해서 특정 메모리를 찾는게 그것이 상대주소이다. 예를 들어 어떤 PC 메모리 주소가 0부터 999까지 있다고 했을 때 이 중 어딘가를 어느 프로세스가 쓰고 있는데 이 메모리 주소가 400이라고 가정했을 때 0번지부터 400번째 떨어진 곳 이것이 절대주소이고 사용자영역 360부터 40만큼 떨어진 곳이라고 표현하는 것은 상대주소이다. 즉, 상대주소는 논리적 메모리 주소이고 논리적은 가상이기 때문에 가상메모리에서 상대주소 애기가 나오는 것이다. 가상메모리 체계에서 RAM메모리의 0~3번지까지 OS가 사용한다고 가정해보자. 근데 Process1의 VMS에 0번지가 실제 RAM 7번지와 매핑되었다고 했을 때 절대주소는 7이 되는 것이고 상대주소는 0이 되는 것이다. 그리고 Process1이 종료되면 Process1이 쓰는 공간을 OS가 회수한다.

그러면 한번 코드로 알아보자.

```c++
#include <iostream>

int g_data = 20;

int main() {
  int a = 16;
  int b = 32;
  int c = 64;

  printf("%p: %d\n", &a, a);
  printf("%p: %d\n", &b, b);
  printf("%p: %d\n", &c, c);

  *((int *)0x0041A008) = 32;
  printf("%d\n", g_data);

  int arList[3] = {16, 32, 64};
  printf("%p: %d\n", arList, arList[2]);
}
```

여기서 g_data 전역변수와 a,b,c 지역변수가 존재하는데 디스어셈블리를 해보면 g_data는 절대주소를 사용하고 a, b, c는 상대주소를 사용한다.

> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## 메모리 오버레이와 스왑

메모리의 오버레이와 스왑 자체가 Virtual Memory System을 이야기하고자 하는 초석이다. 핵심은 바로 다음과 같다. 어떤 C언어로 작성된 S/W가 있고 C언어는 CPU가 알아들을 수 있게 번역하여 기계어로 만들어 주는데 기계어 코드가 프로세스 내의 모듈이 되고 메모리의 OS영역, 공통모듈영역(DLL)을 제외한 사용자 영역에 집어넣어서 하는 것이 연산의 실행이다.

문제는 OS는 옛날에 MS-DOS를 썼는데 이때 시절 OS는 역할이 단순 I/O 해주는 거 외에는 별거 없었다. 그러다 보니 S/W 개발자가 모든 처리를 직접 하는 일이 많았다. 중요한 것은 기계어를 사용자 영역에 로드하여 작동되다가 그 프로그램을 끝내고 다른 걸 실행하려고 하면 메모리 용량이 옛날에는 640KB로 너무 적어서 그 프로그램이 쓰던 메모리를 clear 하고 그다음 프로그램을 로딩해서 집어넣는 형식이었다. 그러니까 메모리 위에 메모리가 overwrite 되어 겹겹이 쌓인다. 이걸 메모리의 오버레이라고 한다. 그래서 이런 부분들이 문제가 되다보니까 나중에는 RAM이 작아가지고 프로그램을 실행 못하는 이런 일이 있었고 옛날에는 이걸 HDD와 연동하여 RAM에 있는걸 잠시 HDD에 보내고 HDD의 정보를 RAM에 가져와 실행하는 이 과정들을 반복하였는데 여기서 나오는 말이 스왑이다. HDD 같은 2차 메모리에 스왑영역을 두어서 스왑영역 + RAM = 실제 PC가 쓸 수 있는 메모리 공간이라 했으며 RAM에서 HDD로 내보내는 걸 스왑 아웃 그 반대를 스왑인이라고 한다. 스왑인은 뭔가 실제로 CPU한테 연산할 수 있도록 빨리 정보를 주니까 그래서 스왑인을 하는 거고 잘 안 쓰이는 프로그램은 HDD로 빼는 게 스왑아웃이다. 여기서 스왑인은 가상메모리 이야기할 때 페이지인과 같은 개념이고 스왑아웃은 페이지 아웃과 같은 개념이다.

> 최대 절전모드는 RAM 메모리에 정보가 들어가져 있는데 이걸 그냥 HDD에 저장해가지고 전원이 꺼져도 다시 킬 때 작업했던 상태를 복구할 수 있는데 바로 그 이유다. 여기서 RAM 전체 메모리가 HDD에 들어가는 게 아니라 사용되고 있는 용량만큼만 들어간다.

> 옛날에는 스왑인, 스왑아웃 이 과정들이 자주 벌어졌는데 이래서 SSD가 등장하고 체감속도가 급상승되었다. 그 이유가 스왑아웃할 때 SSD에 write가 일어나는데 HDD는 트랙 섹터로 자기판을 돌아서 정보를 가져오는 방면 SSD는 전자로 빠르게 치고 나가기 때문에 I/O과정에서 속도 급상승이 컴퓨터 속도가 급상승으로 이어온 것이다.

> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## 메모리 분할 방식

지금까지 우리가 이야기했던 메모리는 물리 메모리이다. 근데 솔직히 몰라도 사는데 지장은 없다. 왜냐하면 이것은 알아서 잘 되고 있기 때문이다. 아무튼 그래도 나는 계속 이야기를 이어나가 보겠다. 이런 물리 메모리를 관리하는 방법이 크게 2가지가 존재하는데 가변분할 방식과 고정분할 방식이 있다. 이 물리 메모리를 꼭 써야 하는 이유는 여기에 올라가는 게 어떤 S/W의 기계어가 올라간다. 이 기계어를 하나씩 잘라다가 CPU가 연산을 해야 하니까 그러기 위해서 1차 메모리에 로딩을 하는 건데 문제는 이 S/W의 크기가 얼마나 되는지 알 수가 없다. 왜냐하면 프로그램마다 크기가 제각각이기 때문이다. 그런데 가변분할방식은 만약 프로그램이 동시에 여러 개 작동한다면 이 프로그램들이 프로세스가 되고 이 프로세스들을 연속된 공간에 할당되고 이것의 단위를 세그먼트라고 부른다. 이 세그먼트들은 크기가 각각 다르다. 그리고 고정분할방식은 어떤 일정단위(page)로 짤라 놓은 거에 대해서 할당한다, 만약 page가 20KB인데 프로세스 크기가 40KB이면 이 프로세스를 2개로 쪼갠다. 그리고 쪼개진 것들이 같이 붙어있을 수도 있겠지만 다른 곳으로 각각 떨어질 수도 있는데 이는 OS 처리방식마다 다르다. 그리고 또 알아두어야할께 가변분할이든 고정분할이든 빈 공간(자투리 공간)이 생기는데 또 다른 용어로 단편이라고 하고 이 단편(조각)들을 조각모음해줘야 한다.

> 흔히 요즘 OS는 가변분할 + 고정분할 합성해서 같이 쓴다.

가변분할방식을 쓰면 장점은 메모리를 촘촘하게 쓸 수 있지만 문제점은 이 메모리 중간을 쓰던 프로세스가 종료되면 쓰고 있던 메모리를 회수한다. 그런데 또 다른 프로세스가 동작하게 되면 그 프로세스가 종료된 프로세스 크기보다 크게 되면 문제 즉, 관리적 이슈가 발생한다. 어떻게 보면 관리적 측면에서 고정분할의 로직이 더 단순하다. 아무튼 다시 예를 들면 프로세스 A,B,C,D,E를 실행순서 데로 놓는다. 그런데 중간의 B와 D가 종료되면 중간에 메모리 공간이 비게 된다. 이건 것을 외부단편화라고 한다. 이런 것들을 나중에 조각모음을 해주는데 이런 조각모음을 위해 빈 공간들을 한쪽에 몰아놓으려면 기존 프로세스들이 이동해야 하는데 그러면 메모리 MOVE가 일어나는데 이 조각모음이 그래서 좋을 수도 있고 안 좋을 수도 있다. 왜냐하면 이 조각모음 자체가 CPU를 사용하는 일이고 이것도 OS연산을 수반하기 때문에 잘하는 것인지는 생각해봐야 한다.

> 요즘은 SSD로 바뀌면서 조각모음이 필요가 없어졌는데 조각을 접근할때 HDD에 비해 어느 섹터, 트랙이든 일정속도로 다 되다 보니까 굳이 필요가 없어졌다.

| 구분        | 가변 분할 방식                   | 고정 분할 방식             |
| ----------- | -------------------------------- | -------------------------- |
| 메모리 단위 | 세그먼테이션                     | 페이징                     |
| 특징        | 연속 메모리 할당                 | 비연속 메모리 할당         |
| 장점        | 프로세스를 한 덩어리로 관리 가능 | 메모리 관리가 편함         |
| 단점        | 빈 공간의 관리가 어려움          | 프로세스가 분할되어 처리됨 |
| 단편화      | 외부 단편화                      | 내부 단편화                |

> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## 가상 메모리 개요

운영체제에서 가장 중요한 것이 가상메모리이다. 가상메모리 체계가 사실상 시스템 프로그래밍을 다루는 내용 중에 가장 중대한 요소이다. 우선 가상메모리에 대해 조금 얘기해보자면 어떤 PC가 있는데 PC의 스펙이 PC마다 실제 메모리 크기가 다르다. 즉, RAM의 용량과 HDD용량 제각각이다. 즉, 물리메모리라는 것은 크게 2가지인데 1차 메모리이냐 아니면 2차 메모리이냐는 것이다. 근데 중요한 것은 메모리 크기가 서로 다르니까 이때마다 어떤 S/W가 여기에 대해 의존성이 존재해서 그때마다 코드를 변경해야 한다고 해보자. 그러면 개발측면에서 매우 난감할 것이다. 그런데 실제로 옛날에는 그랬지만 오늘날 범용 OS가 등장하고 그럴 필요가 없어졌다. 그래서 이 S/W를 어떤 가상화 형식 위에서 실행하다 보니까 메모리가 어떤 용량이든 잘 실행될 수 있도록 만들어주는 체계로 가상메모리가 필요해졌다. 그뿐만 아니라 이 가상메모리 안에 들어가 있는 것 중에 장치에 대한 의존성이 있는데 특히 메모리에 대한 의존성이 있는데 이 의존성을 없애는 역할도 하고 더 중요한 것은 관리적인 측면에서 추상성을 제공한다는 것이 매우 중요한데 이 추상성 제공으로 인해서 보안이 올라갔다. 즉, 접근통제가 가능해졌다는 것이다. 이게 굉장히 큰 의미가 있다. 그리고 가상메모리 체계든 물리 메모리 체계든 중요한 것은 메모리의 관리의 최소단위가 1byte인데 이 1byte마다 주소가 붙는데 이 주소가 32bit 체계면 최대용량 4GB이다. 아무튼 이때 주소 길이는 OS가 몇 bit냐에 따라 혹은 CPU가 몇 bit냐에 따라 의존적이다. 그래서 가상메모리가 나오면 일단 중요한 건 주소의 bit수부터 따져야 한다. 만약 64bit platform을 쓴다고 하면 주소 bit수가 64bit인거고 나올 수 있는 전체 경우의 수는 16EB이다. 만약 예를 들어 32bit platform이다고 하면 응용 S/W가 32bit이면 VMS를 보통 반으로 짤라서 앞에 2GB, 뒤에 2GB 잘라서 쓴다. 그래서 앞에 2GB를 user-mode 영역이라고 하고 뒤에 2GB를 kernel 영역이라고 한다. 그리고 앞에 2GB 중 0번지부터 어느 정도는 OS가 사용하고 있다. 그래서 user-mode에서 쓸 수 있는 용량의 크기가 1.8GB 정도이다. 그래서 C언어로 malloc()을 2GB 할당 요청하면 에러가 발생한다. 가상메모리에서 메모리 관리자가 사용할 수 있는 메모리 전체 크기는 물리 메모리와 스왑영역을 합한 크기이다. 여기서 메모리 관리자는 커널쪽에 존재한다. 이 메모리 관리자가 OS 중에서 굉장히 중요한 핵심요소 중 하나다. 근데 요즘은 특별한 이유가 없다면 swap영역의 크기를 OS가 알아서 조절한다. swap이 늘면 용량이 늘어서 좋지만 swap이 자주 일어나면 I/O 효율이 굉장히 떨이지기 때문이다. 아무튼 VMS에서 메모리 관리자는 물리 메모리와 스왑영역을 합쳐서 프로세스가 사용하는 가상주소를 실제 메모리의 물리주소로 변환하는데 이러한 작업을 동적주소변환이라고 한다. 즉, 동적주소변환의 동적은 runtime이라는 것 즉, 프로세스가 실행 중인 중간에 주소체계를 뭔가 변환한다는 것이다. 여기서 주소체계를 잠시 얘기하면 물리적인 수준에서 주소얘기를 하면 이때는 세그먼테이션으로 가는데 user-mode에서 프로세스 VMS를 일정단위로 자르는데 이걸 페이지라고 한다. 그래서 세그먼테이션 하고 페이징하고 섞어가지고 쓰는데 이걸 같이 이야기한다.

좀 정리하면 VMS에서 가변분할방식을 이용하는 기법을 세그먼테이션, 고정분할방식을 이용한 기법을 페이징이라고 한다. 그래서 예를 들어 hello-world 콘솔 어플리케이션이 있다고 보자, 중요한 것은 이 S/W가 실제 쓰는 메모리는 2GB 전부 사용할까? 실제로는 그렇지 않고 많이 줘도 1MB 정도 쓸 것이다. 예를 들어 위의 그림의 프로세스3가 진짜 쓰는 실제 RAM의 메모리 주소가 10이다고 해보자. 하지만 VMS에서는 메모리 주소가 100을 가리킬 수 있다. VMS시작은 메모리 주소 0부터인데 웃긴 것은 프로세스마다 VMS 체계에서는 각자 고유의 메모리 주소를 갖기 때문에 각 프로세스 VMS의 0번지라도 실제 RAM은 다를 수 있다. 그래서 물리적 메모리 위치를 두고 봤을 때는 당연히 다른 위치가 되는 것이고 심지어 경우에 따라 swap 되었다고 하면 HDD로 갈 수 있는 것이다. 어쨌든 물리 메모리상의 주소가 절대주소가 부여되어 있는데 그 기준주소를 두고 즉, 프로세스마다 같은 주소를 말한다 하여 물리메모리는 다른 주소이다. 어느 프로세스A가 메모리를 쓰고 있으면 메모리 매니저 안에 매핑 테이블이 있는데 이 매핑 테이블에 가보면 프로세스 A의 0번 위치가 물리메모리의 세그먼트 0번에 존재한다 이런 식으로 표기되어 있다. 그리고 매핑테이블은 물리메모리가 세그먼테이션으로 분할된 경우뿐만 아니라 페이징으로 분할된 경우에도 똑같은 방식으로 적용된다.

> 매핑테이블은 자료구조로 배열일 가능성이 있다.

매핑테이블을 OS가 관리하고 있는데 그래서 좋은점이 만약에 프로세스 A가 잘못된 연산을 하여 죽으면 매핑 테이블의 프로세스 A 칼럼을 날려버리고 가리키고 있던 세그먼테이션 0번을 여분의 공간으로 빼버린다. 즉, 관리를 잘해준다. 가상메모리를 썼을 때 굉장히 좋은점이 만약 프로그램이 죽으면 이 프로그램이 연결되어 있던 모든 체계를 메모리 매니저가 알고 있기 때문에 신속히 회수가 가능하고 자원낭비가 없다. 만약 물리 메모리가 잘못되어서 OS가 공간회수를 못하게 되면 재부팅을 해야 한다. 좋은 OS일수록 Application의 가상화정도가 높다. 대표적인 예로 모바일 OS이다. 생각해 보면 어플이 죽었다 해서 우리가 모바일을 재부팅한 적은 없을 것이다.
