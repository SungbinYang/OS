> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## 메모리 관리 개요

물리 메모리라는 것은 예로 512KB라는 것은 옛날에 8088XT라는 PC가 있었는데 이 PC CPU성능이 10 MHz정도 된다.

근데 상식적으로 알아야 할 내용이 뭐냐면 메모리는 총 2분류로 나눠지는데 RAM이라는 1차 메모리가 있고 SSD 혹은 HDD라는 2차 메모리가 있다. 여기서 메모리 주소 애기가 나오는데 메모리라고 하는 것에 대해서 어느 공간을 일부 잘라서 그 공간에 일련번호를 붙이는데 그 일련번호를 메모리 주소라고 한다. 또한 이 메모리 주소가 붙은 메모리의 일정한 단위 크기는 1byte이다. 즉, 1byte 메모리마다 주소가 붙는다. 근데 이 주소가 32bit 체계이면 최대크기가 2^32 = 4GB 정도가 나온다. 만약 64bit라고 하면 2^64 = 16EB 정도 나온다. 그래서 웃긴게 옛날에 32bit OS를 설치하고 RAM을 8GB를 장착하면 4GB밖에 인식을 못했는데 그 이유가 위에 설명한 이유에서 비롯된 것이다. 그러면 64bit platform에선 16EB RAM을 꽂으면 다 인식이 가능할까? 사실상 불가능하고 인식할 수 있는 RAM은 버전마다 다르지만 윈도우 홈버전 기준으로 128GB까지 인식이 되고 pro버전 이상은 2TB까지 인식이 가능하다.

## 컴파일러, 인터프리터

컴퓨터에서 연산을 하는 주체는 CPU이다. CPU가 연산을 하는 주체이긴 하지만 속도도 굉장히 빠르다. CPU에 연산할 거리들이 쭉 나열되어 있는데 CPU는 이 연산할 거리들을 끄집어내서 실행을 하려 한다. 근데 문제는 CPU는 실행하려 하는데 연산거리는 누군가 추가를 해줄 것이다. 즉, 해야할 일이 쌓여있다는 것은 CPU 연산속도가 추가하는 속도보다 더디다는 것이고 반대로 할 거리들이 비어있다는 것은 자원의 낭비가 발생한다. 이런 것들 때문에 등장하는 것이 캐시이다. 연산이 실행될때는 CPU가 인식 가능한 코드(기계어)로 바꿔야 하고 프로그램들은 일반적으로 C나 Python 등 프로그래밍 언어로 작성하는데 이 코드들을 기계어로 번역해 주는 과정이 컴파일 혹은 인터프리터라고 한다.

> 빠른 실행을 위해 이런 일거리들을 보통 RAM에 올려놓고 사용한다.

## 메모리 매니저

HDD의 정보를 RAM에 복사하고 그 RAM이 CPU에 정보를 복사하는 일련의 과정에서 개입하는 요소가 있는데 그게 메모리 매니저이다. 메모리 매니저가 하는 역할은 **가져오기, 배치, 재배치**이다. 이중에 가장 중요한 역할이 **배치정책**이다.

배치정책을 왜 애기하냐면 예를 들어 RAM이라는 공간은 한정되어 있는데 그런데 그 위에 작동하는 프로세스가 여러 개 있을 때 이 프로세스들 전부 빠른 연산을 위해 RAM을 쓰고 싶어 한다. 하지만 RAM의 기억공간은 한정적이기 때문에 이 프로세스들이 동시에 작동하기 위해서는 재배치 작업이 필요하다. 즉, RAM이 가득 찼을 때 연산을 별로 안 하는 프로세스를 HDD로 옮기고 그 자리에 다른 프로세스를 배치한다. 이때 배치를 할 때 사용하는 단위가 page이다.

> 배치정책: 가져온 프로세스를 어떤 위치에 올려놓을지 결정하는 정책  
> 페이징: 메모리를 같은 크기로 자르는 것을 말한다.  
> 세그먼테이션: 프로세스의 크기에 맞게 자르는 것을 말한다.  
> 세그먼트: 메모리를 Stack, Heap, Text, Data영역등으로 나누는데 그때 나누는 것을 말한다.

> 기본적으로 OS는 page단위로 메모리를 통제하고 윈도우 기준 page크기는 4KB이다.
