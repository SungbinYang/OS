> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## 메모리 관리 개요

물리 메모리라는 것은 예로 512KB라는 것은 옛날에 8088XT라는 PC가 있었는데 이 PC CPU성능이 10 MHz정도 된다.

근데 상식적으로 알아야 할 내용이 뭐냐면 메모리는 총 2분류로 나눠지는데 RAM이라는 1차 메모리가 있고 SSD 혹은 HDD라는 2차 메모리가 있다. 여기서 메모리 주소 애기가 나오는데 메모리라고 하는 것에 대해서 어느 공간을 일부 잘라서 그 공간에 일련번호를 붙이는데 그 일련번호를 메모리 주소라고 한다. 또한 이 메모리 주소가 붙은 메모리의 일정한 단위 크기는 1byte이다. 즉, 1byte 메모리마다 주소가 붙는다. 근데 이 주소가 32bit 체계이면 최대크기가 2^32 = 4GB 정도가 나온다. 만약 64bit라고 하면 2^64 = 16EB 정도 나온다. 그래서 웃긴게 옛날에 32bit OS를 설치하고 RAM을 8GB를 장착하면 4GB밖에 인식을 못했는데 그 이유가 위에 설명한 이유에서 비롯된 것이다. 그러면 64bit platform에선 16EB RAM을 꽂으면 다 인식이 가능할까? 사실상 불가능하고 인식할 수 있는 RAM은 버전마다 다르지만 윈도우 홈버전 기준으로 128GB까지 인식이 되고 pro버전 이상은 2TB까지 인식이 가능하다.

## 컴파일러, 인터프리터

컴퓨터에서 연산을 하는 주체는 CPU이다. CPU가 연산을 하는 주체이긴 하지만 속도도 굉장히 빠르다. CPU에 연산할 거리들이 쭉 나열되어 있는데 CPU는 이 연산할 거리들을 끄집어내서 실행을 하려 한다. 근데 문제는 CPU는 실행하려 하는데 연산거리는 누군가 추가를 해줄 것이다. 즉, 해야할 일이 쌓여있다는 것은 CPU 연산속도가 추가하는 속도보다 더디다는 것이고 반대로 할 거리들이 비어있다는 것은 자원의 낭비가 발생한다. 이런 것들 때문에 등장하는 것이 캐시이다. 연산이 실행될때는 CPU가 인식 가능한 코드(기계어)로 바꿔야 하고 프로그램들은 일반적으로 C나 Python 등 프로그래밍 언어로 작성하는데 이 코드들을 기계어로 번역해 주는 과정이 컴파일 혹은 인터프리터라고 한다.

> 빠른 실행을 위해 이런 일거리들을 보통 RAM에 올려놓고 사용한다.

## 메모리 매니저

HDD의 정보를 RAM에 복사하고 그 RAM이 CPU에 정보를 복사하는 일련의 과정에서 개입하는 요소가 있는데 그게 메모리 매니저이다. 메모리 매니저가 하는 역할은 **가져오기, 배치, 재배치**이다. 이중에 가장 중요한 역할이 **배치정책**이다.

배치정책을 왜 애기하냐면 예를 들어 RAM이라는 공간은 한정되어 있는데 그런데 그 위에 작동하는 프로세스가 여러 개 있을 때 이 프로세스들 전부 빠른 연산을 위해 RAM을 쓰고 싶어 한다. 하지만 RAM의 기억공간은 한정적이기 때문에 이 프로세스들이 동시에 작동하기 위해서는 재배치 작업이 필요하다. 즉, RAM이 가득 찼을 때 연산을 별로 안 하는 프로세스를 HDD로 옮기고 그 자리에 다른 프로세스를 배치한다. 이때 배치를 할 때 사용하는 단위가 page이다.

> 배치정책: 가져온 프로세스를 어떤 위치에 올려놓을지 결정하는 정책  
> 페이징: 메모리를 같은 크기로 자르는 것을 말한다.  
> 세그먼테이션: 프로세스의 크기에 맞게 자르는 것을 말한다.  
> 세그먼트: 메모리를 Stack, Heap, Text, Data영역등으로 나누는데 그때 나누는 것을 말한다.

> 기본적으로 OS는 page단위로 메모리를 통제하고 윈도우 기준 page크기는 4KB이다.

> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## 절대주소와 상대주소

메모리라고 하는 것에 대해서 어느 한 단위가 있는데 크기가 1byte가 되는 것이고 이 1byte마다 메모리 주소가 붙는데 이 주소가 64bit 체계이면 64bit system, 32bit 체계이면 32bit system이라고 불린다. 근데 이것이 Application 수준에도 적용된다. 중요한 것은 RAM에는 하드웨어 수준에 부여된 주소체계가 있고 Application Process수준에 부여된 주소체계가 있는데 이 둘이 조금 다르다. 즉 이 둘의 차이가 있는데 애네 둘이 서로 다른 번호를 쓰게 되는데 왜냐하면 이 둘은 가상메모리 체계를 쓰기 때문에 이 두 주소는 일치하지 않는다. 그래서 메모리의 어떤 주소를 얘기할 때는 2가지 기준으로 간다. 절대주소와 상대주소로 가는데 쉽게 생각해서 배열을 생각하면 된다. 어떤 배열이 있으면 배열의 이름이 주소인데 이 주소를 가지고 어느 특정 메모리를 식별이 가능하다. 상대주소는 배열의 인덱스 연산(인덱싱)해서 특정 메모리를 찾는게 그것이 상대주소이다. 예를 들어 어떤 PC 메모리 주소가 0부터 999까지 있다고 했을 때 이 중 어딘가를 어느 프로세스가 쓰고 있는데 이 메모리 주소가 400이라고 가정했을 때 0번지부터 400번째 떨어진 곳 이것이 절대주소이고 사용자영역 360부터 40만큼 떨어진 곳이라고 표현하는 것은 상대주소이다. 즉, 상대주소는 논리적 메모리 주소이고 논리적은 가상이기 때문에 가상메모리에서 상대주소 애기가 나오는 것이다. 가상메모리 체계에서 RAM메모리의 0~3번지까지 OS가 사용한다고 가정해보자. 근데 Process1의 VMS에 0번지가 실제 RAM 7번지와 매핑되었다고 했을 때 절대주소는 7이 되는 것이고 상대주소는 0이 되는 것이다. 그리고 Process1이 종료되면 Process1이 쓰는 공간을 OS가 회수한다.

그러면 한번 코드로 알아보자.

```c++
#include <iostream>

int g_data = 20;

int main() {
  int a = 16;
  int b = 32;
  int c = 64;

  printf("%p: %d\n", &a, a);
  printf("%p: %d\n", &b, b);
  printf("%p: %d\n", &c, c);

  *((int *)0x0041A008) = 32;
  printf("%d\n", g_data);

  int arList[3] = {16, 32, 64};
  printf("%p: %d\n", arList, arList[2]);
}
```

여기서 g_data 전역변수와 a,b,c 지역변수가 존재하는데 디스어셈블리를 해보면 g_data는 절대주소를 사용하고 a, b, c는 상대주소를 사용한다.

> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## 메모리 오버레이와 스왑

메모리의 오버레이와 스왑 자체가 Virtual Memory System을 이야기하고자 하는 초석이다. 핵심은 바로 다음과 같다. 어떤 C언어로 작성된 S/W가 있고 C언어는 CPU가 알아들을 수 있게 번역하여 기계어로 만들어 주는데 기계어 코드가 프로세스 내의 모듈이 되고 메모리의 OS영역, 공통모듈영역(DLL)을 제외한 사용자 영역에 집어넣어서 하는 것이 연산의 실행이다.

문제는 OS는 옛날에 MS-DOS를 썼는데 이때 시절 OS는 역할이 단순 I/O 해주는 거 외에는 별거 없었다. 그러다 보니 S/W 개발자가 모든 처리를 직접 하는 일이 많았다. 중요한 것은 기계어를 사용자 영역에 로드하여 작동되다가 그 프로그램을 끝내고 다른 걸 실행하려고 하면 메모리 용량이 옛날에는 640KB로 너무 적어서 그 프로그램이 쓰던 메모리를 clear 하고 그다음 프로그램을 로딩해서 집어넣는 형식이었다. 그러니까 메모리 위에 메모리가 overwrite 되어 겹겹이 쌓인다. 이걸 메모리의 오버레이라고 한다. 그래서 이런 부분들이 문제가 되다보니까 나중에는 RAM이 작아가지고 프로그램을 실행 못하는 이런 일이 있었고 옛날에는 이걸 HDD와 연동하여 RAM에 있는걸 잠시 HDD에 보내고 HDD의 정보를 RAM에 가져와 실행하는 이 과정들을 반복하였는데 여기서 나오는 말이 스왑이다. HDD 같은 2차 메모리에 스왑영역을 두어서 스왑영역 + RAM = 실제 PC가 쓸 수 있는 메모리 공간이라 했으며 RAM에서 HDD로 내보내는 걸 스왑 아웃 그 반대를 스왑인이라고 한다. 스왑인은 뭔가 실제로 CPU한테 연산할 수 있도록 빨리 정보를 주니까 그래서 스왑인을 하는 거고 잘 안 쓰이는 프로그램은 HDD로 빼는 게 스왑아웃이다. 여기서 스왑인은 가상메모리 이야기할 때 페이지인과 같은 개념이고 스왑아웃은 페이지 아웃과 같은 개념이다.

> 최대 절전모드는 RAM 메모리에 정보가 들어가져 있는데 이걸 그냥 HDD에 저장해가지고 전원이 꺼져도 다시 킬 때 작업했던 상태를 복구할 수 있는데 바로 그 이유다. 여기서 RAM 전체 메모리가 HDD에 들어가는 게 아니라 사용되고 있는 용량만큼만 들어간다.

> 옛날에는 스왑인, 스왑아웃 이 과정들이 자주 벌어졌는데 이래서 SSD가 등장하고 체감속도가 급상승되었다. 그 이유가 스왑아웃할 때 SSD에 write가 일어나는데 HDD는 트랙 섹터로 자기판을 돌아서 정보를 가져오는 방면 SSD는 전자로 빠르게 치고 나가기 때문에 I/O과정에서 속도 급상승이 컴퓨터 속도가 급상승으로 이어온 것이다.
