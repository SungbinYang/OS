> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## CPU 스케줄링 개요

### 스케줄링 개요

컴퓨터 세상을 국가라고 했을 때 프로세스가 한 가정이고 그 가정 속에 한 개인이 스레드이다. OS는 일종의 프로그램(프로세스)으로 백그라운드에서 실행이 된다. OS는 user-mode-application 영역의 process들을 support 한다. 즉, 프로세스들은 스케줄링 한다는 것은 가장 중요한 것은 프로세스를 식당의 손님이라고 하면 이 프로세스 안의 스레드들이 CPU 자원을 소모한다. 스레드는 어떤 프로세스 안에 속해 있는데 이 프로세스를 또 하나의 그룹으로 묶일 수 있는데 그 그룹이 Job이다. 스케줄링이란 OS가 프로세스 줄 세우기를 하는 것인데 CPU의 핵심적인 전산자원을 스레드들이 **_선점하는_** 방식이다. 쉽게 말해 OS가 스레드들을 줄을 세워서 '너 이 만큼 가져가~'라고 하는 것이다.

스케줄링 단계에서는 크게 3단계로 나눠지는데 이제까지 우리가 얘기했던 것들이 Lv3 저수준 스케줄링이다. 즉, 스레드들이 대기되면 OS가 '너 잠깐 비켜봐'라고 하는 것들이 저수준 스케줄링이다. Lv1 고수준 스케줄링은 다른 말로 장기 스케줄링 혹은 Job 스케줄링이라고 부르는데 이때 Job이 위에서 언급한 프로세스가 속한 그룹이다. 이 수준의 스케줄링은 전체적인 시스템의 부하상태를 고려한다. 즉, 시스템의 전체적인 부하상태 즉, 큰 틀에서의 현재 부하상태를 고려하고 CPU를 어떻게 나눠야 할지를 판단해야 한다. 쉽게 애기해보면 고수준 스케줄링이 식장의 전체 손님 수를 조절한다고 하면 저수준 스케줄링은 각 손님의 주문과 그에 따른 요리제공 순서를 미세하고 조절하는 작업이라고 볼 수 있다. 중간 수준 스케줄링은 대기줄을 서는 손님을 관리하는 것이다. 결론적으로 고수준이든 저수준이든 중간수준이든간에 이런 것들이 존재하는 이유는 기본적으로 시스템의 과부하 상태를 막는 것이다. 그러다 보니 프로세스가 새로 생성된다고 해도 일단 대기상태에 있다가 20명의 정원 식당에서 20명까지는 활성화 프로세스가 되는 것이고 그 외 나머지는 보류 프로세스가 되는 것이다.

> 스케줄링의 목적
>
> 1.  공평성
> 2.  효율성
> 3.  안정성
> 4.  확장성
> 5.  반응 시간 보장
> 6.  무한 연기 방지

### 스케줄링 시 고려 사항

스케줄링에는 선점형 스케줄링이 있고 비선점형 스케줄링이 있다. 선점형은 이제까지 우리가 설명한 것인데 예를 들어 Excel이라는 프로그램과 word라는 프로그램이 작동 중인데 Excel이 CPU를 쓰는 동안 word는 wait상태가 되고 OS가 Excel을 대상으로 wait를 하면 Excel이 wait상태가 되고 word가 활성화 상태가 된다. 이것이 선점형 스케줄링이다. 즉, 어떤 프로세스가 CPU자원을 선점해서 쓰려고 하는데 그걸 OS가 통제할 수 있는 상황이면 선점형이다. 보통의 상황의 경우 선점형 방식을 채택한다. 비선점형 방식은 선점형 방식 정반대이다. 일단 일이 시작되면 이 일이 끝날 때까지 다른 일은 wait상태이다. 즉, 어떤 프로세스가 CPU를 점유하면 다른 프로세스가 이를 뺏을 수 없는 스케줄링 방식이다. 물론 OS는 강제로 뺏을 수 있긴 하다.

> 그래서 일반적인 경우 선점형이고 특이한 경우만 비선점형 방식을 채택한다.

스케줄링을 애기하면 우선순위 애기가 딸려 나온다. Process + Thread별로 우선순위를 정할 수 있는데 이 우선순위는 아래와 같이 5단계로 나뉜다.

> 매우 낮음 < 약간 낮음 < 보통 < 약간 높음 < 매우 높음

일단 프로세스를 띄우면 보통단계로 시작을 하는데 미디어 플레이어와 같이 4K 영상을 시청하는 경우 성능이 안 좋으면 영상이 뚝뚝 끊기고 플레이어가 맛이 갈 경우가 있는데 이런 경우는 약간 높음이나 매우 높음으로 우선순위를 높여줘야 하고 압축해제 같은 백그라운드 작업은 우선순위를 매우 낮음 혹은 약간 낮음으로 설정해 주면 효율적인 우선순위 방식이다. 즉, GUI를 가지는 전면부는 끊기거나 이상이 있으면 클라이언트들이 바로 컴플레인이 들어오지만 백그라운드 처리로직은 사용자들이 모르기 때문에 우선순위를 낮춰줘야 한다.

예를 들면 느린 I/O가 되면 특정 CPU를 선점해서 오랬동안 lock을 걸고 wait을 한다. 매우 낭비이다, 그러면 이런 처리는 비동기 처리를 해야 하는 거고 이래서 non-blocking I/O가 나오는 것이다. 이렇게 비동기처리를 하고 GUI부분이 살아있다고 표시를 해줘야 사용자들의 불편이 없을 것이다. 그런데 가끔 백그라운드 작업의 우선순위를 높여줘야 할 때가 있다. 그런 환경이 서버같은 경우가 그렇다.

### 정리

스케줄링 우선순위에 대해서 전면 프로세스보다 더 높은 우선순위를 가지는게 있는데 그게 바로 커널 프로세스다. 그러면 여러분은 IOCP가 왜 빠른지 이해가 될 것이다. IOCP는 Kernel I/O를 하는 역할을 하기 때문이며 커널 프로세스가 가장 높기 때문에 빠른 것이다.

> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## 프로세스 간 통신 개요 (= IPC)

IPC는 면접 때도 질문이 진짜 많이 나오는 내용으로 잘 알아두자! 프로세스라는 것은 공간이 독립적으로 부여된다. 무슨 말이냐면 메모리 공간이 주어지는데 이 메모리공간에 대해 다른 프로세스가 접근하지 못하도록 외부접근 차단하는 것을 OS가 보장한다. 만약 이것을 안 해주면 내가 저장해 놓은 data를 외부에서 변경시키는 일이 벌어진다. 물론 이것을 의도적으로 해야 할 때가 있는데 DMA나 마이컴등이 이런 경우이다. 아무튼 이런 것은 정말 특수한 경우가 아니면 안 된다. 만약 OS가 보장하는 것을 뚫고 data를 변경을 시키면 그것은 일명 해킹이라고 부른다. 프로세스가 사용하는 전산자원 중에는 독립적인 메모리뿐만 아니라 파일형태로 쓰는 게 있는데 이것을 대표적으로 파이프라고 한다.

추가적으로 알아야 할것이 있는데 프로세스 간의 통신을 할 수 있는 방법으로는 크게 보면 메모리를 이용하는 방식, 쉽게 말해 RAM을 쓰는 것이고 그다음으로는 file을 이용하는 방식이 있다. 이 2가지 방법이 차이가 있는 것이 file 하면 떠올라야 하는 것이 stream이며 file은 시작이 있지만 끝이 조금 애매하다는 것이 특징으로 볼 수 있다. 우리가 fOpen() 함수를 통해 파일을 만들면 처음에는 size가 0이다. 조금 웃긴 상황이 우리는 여기다가 write() 함수를 통해 데이터를 넣는다. 그 후에 size는 자동증가가 된다. 얼마나 증가하냐면 이 file을 컨트롤해 주는 파일 시스테이 제공하는 한계까지 늘어날 수 있다. 그런데 RAM을 쓸데는 가장 중요한 특징이 고정길이이다. RAM은 자원이 매우 제한적이기 때문에 OS한테 요구를 할 때 OS가 얼마나 쓸 것인지 강하게 체크한다. 즉 길이를 OS가 강하게 검사를 하는 것이다. 그래서 우리는 할당단계에서 크기를 고정해야 한다. 만약, IPC가 네트워크 개념까지 확장되면 소켓이 등장한다. 이 소켓을 기반으로 TCP 연결이 된 상태에서 또 다른 개념으로 RPC가 나오는데 RPC는 원격 함수 호출로 이 호출을 위해 TCP통신을 한다. 이 부분도 옛날에 쓰던 기술이었는데 최근에 잘 안 쓰다가 오늘 와서 갑자기 급부상하게 되었는데 그 이유가 RCP가 HTTP3와 관련이 있기 때문이다. 오늘날의 HTTP는 아주 옛날의 TCP와 같은 역할을 하고 있다. 이래서 Web Socket 개념이 나오기 시작했고 이런 개념을 이해하기 시작하면서 RPC 개념이 확장되었다. 웹 기반으로 하는 (HTTP를 기반으로) RPC도 고민해야 한다.

본론으로 IPC방법론이 여러가지 있는데 기본적으로 파이프라고 나오면 파일이라 생각하면 된다. 즉, data를 직렬화시켜서 stream으로 data를 주거니 받거니 하면 굉장히 유리한 구조이다. 프로세스 간에 독립적인 메모리 공간을 보장한다. 그래서 VMS들은 프로세스들한테 attach 되어 있다. 즉, 다른 프로세스가 내 프로세스 VMS 접근이 안된다. 그래서 IPC는 Shared Memory 기반의 기법을 사용하는데 방법은 다음과 같다.

> A라는 프로세스의 VMS의 어느부분을 따라갔을 때 B라는 프로세스의 VMS의 어느 부분과의 실제 RAM 메모리 주소가 일치한다면 A가 3을 저장했다고 했을 때 B는 3을 읽어 올 수 있다. 반대의 경우도 가능할 것이다.

또 다른 예로 A가 B한테 보낼 정보가 있으면

> 1. A의 VMS에 data를 write 하고
> 2. 그 data가 실제 RAM에 저장될 것이고
> 3. A가 B한테 어떠한 Signal을 보내는데 혹은 Event를 보내는데 그전에 B는 그 Signal이나 Event를 wait상태가 되고
> 4. 그 Event를 받으면 B가 반환시키고
> 5. 그 data를 읽어 들인다.

> 전역변수를 통한 양방향 통신: Shared Memory를 확보한 다음에 앞에는 A가 쓰고 B 쪽에서는 읽어가고 뒤쪽은 반대로 한다, 근데 중요한 것은 Shared Memory를 쓸 때는 길이가 고정되어 있다.

파일의 경우는 되게 독특한 게 뭐냐면 한쪽에서 읽고 한쪽에서 쓰는 방식을 채택한다. data가 섞일 일도 없고 동기화를 덜 신경 써도 되기 때문에 직렬화한 데이터를 넘길 때 유리하다.

> 💡 Tip  
> 우리가 IPC를 할 때 메모리, 파이프, 소케가 RPC 등을 사용하는데 추가적으로 윈도 OS 한정으로 Registry가 있다. 이 레지스트리는 파일보다 더 강력하다. 그리고 레지스트리는 in Memory 상태이다. 그리고 여러 프로세스가 동시접근할 경우 통제도 잘 된다. 즉, file과 Memory의 장점을 둘 다 가졌다. 그래서 레지스트리에다가 I/O를 하면 생각보다 속도가 빠르다. (file에 쓰는 것보다 더 빠르다.)

그런데 가끔 특수한 경우가 있는데 exe파일의 경우 혼자 작동하지 않고 DLL을 로딩해서 작동을 한다. 예를 들어 a.exe가 있는데 a.exe는 a.DLL을 로딩한다. 그런데 b.exe도 a.DLL을 쓸 수가 있다. 즉, DLL은 로딩되고 여러 프로그램이 참조하는 방식으로 되어 있다. 만약에 3개의 프로그램이 실행되고 3개의 프로세스 간에 IPC를 할 수 있을 때 변수 1개 정도를 가지고 뭔가 동기화해야 하는 아주 가끔 이런 상황이 있는데 이 변수 1개를 쉽게 공유하는 방법이 DLL안에 전역변수를 선언하고 그 기억공간을 IPC 하듯이 같이 쓰는 기법이 있는데 그 기법이 data segmant Pragma기법이다. 이 기법은 생각보다 성능이 매우 뛰어나다. 이 기법을 통해 user mode에서 방화벽을 흉내 낼 수 있는데 그중 하나가 WinSocket API를 hook 할 수 있는 방식이다. 이걸 이용한 프로그램이 우리가 인터넷뱅킹을 할 때 설치되는 방화벽 비슷한 프로그램이다. 이 방식을 이용하면 DDL Injection을 하는데 runtime 상태에서 작동되므로 인터넷 뱅킹 사용 시 프로세스를 싹 조사하고 감시하다가 끝나면 끝내는 방식을 취한다.

> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## 공유자원과 임계구역

프로세스든 스레드든 여러 개가 있다고 가정하자. 그런데 여기서 문제가 되는 건 **'동시'에** 어느 한 대상에 접근하면 이때 필연적으로 나타나는 현상이 경쟁조건(race-condition)이다. 아무튼 프로세스가 되었던 스레드가 되었던 여러 개가 동시에 하나의 자원에 접근했을 때 이슈가 나는 것이다.

예를 들어 전역변수로 예금변수 선언 후 10만원으로 초기화했다고 가정해 보자. 다른 한쪽에서는 10만 원을 증가시키는 로직이 있고 다른 한쪽에서는 10만 원을 감소시키는 로직이 있다고 해보자. 그럼 여기서 봐야 할게 10만 원을 증가시키는 이 로직은 예금이라는 변수를 읽어오는 명령어 + 10만 원을 더해주는 명령어 + 다시 예금이라는 변수에 overwrite 하는 명령어 총 3개의 명령어로 구성되어 있다. 10만 원을 감소시키는 로직도 이와 마찬가지이다. 그런데 여기서 CPU는 한 번에 명령 1개씩만 처리하기 때문에 원자성이 보장되지 않으면 뭔가 처리할 때 다른 게 끼어들 수 있다. 즉, 내가 생각하는 결과와 다르게 나올 수 있다. 자세히 보면 이 증가로직과 감소로직을 각각의 별도의 스레드로 처리한다고 했을 때 증가로직에서 10만 원을 더해주는 명령까지 하고 OS가 suspend를 시켰다고 할 때 감소로직에서 10만 원을 감소시키는 로직이 수행되었고 그 이후에 증가로직의 마지막 명령 overwrite가 진행되었다고 하면 10만 원 감소로직으로 0원을 기대했던 사용자는 20만 원이 있는 거에 깜짝 놀랄 것이다.

공유자원이란 우리가 쉽게 생각해서 메모리나 파일정도로 볼 수 있다. 그래서 이런 동시성 이슈에 대해서 원자성을 부여함으로써 동시사건이 안되게 함으로써 예상 이슈를 차단할 수 있다. 그러면 중요한 것이 어떤 연산구문 n개가 있다고 가정하면 이 구문중에 전체에 대해 원자성을 보장한다고 보면 A라는 코드와 B라는 코드가 있다고 가정하고 각각 별도 스레드로 처리한다고 했을 때 A 전체 코드에 대해 원자성을 부여하면 A코드는 코드 시작전에 Lock을 걸어 CPU의 코어가 몇 개든 간에 한 개의 스레드로 처리될 것이고 끝날 때 Unlock을 한다. 만약 Lock을 안 하면 원자성이 손상될 우려가 있다.

임계구간이란 Critical Section으로 말 그대로 위험구간인데 중요한 것은 무엇을 임계구간으로 정하는것이냐이다. 즉, 무엇을 어디서부터 언제 어느 조건으로 임계구간으로 설정해야 하냐는 것인데 이것은 완벽히 경험에 근간한다. 그런데 하나 확실한 것은 이 임계구간을 최소화해야 한다. 왜냐하면 이 구간이 길어지면 길어질수록 효율도 안 좋아지고 또 다른 문제인 DeadLock을 야기할 수 있다. 즉, 임계구간을 없앨 수 있으면 없애는 게 좋고 이 말을 고급지게 Lock-free라고 한다.

> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## 임계구역 해결방법

많은 사람들을 보면 임계구역을 많이들 힘들어한다. 그 이유는 임계구역을 어디를 어떤 근거로 선택하는 것부터 막히기 때문이다. 사실 이 부분에 대한 것은 완벽하게 경험에 비롯된다. 사실 임계구역 해결방법은 정답이라고 할 수 있는 것이 과연 있는지 잘 모르겠다. 왜냐하면 임계구역 설정하는 것이 경험도 중요하지만 더 중요한 것은 현재 상황이다. 전공서에는 임계구역 해결방법으로 상호배제, 한정대기 등등 나와있는 것들이 있지만 그것은 굉장히 일반적인 것이고 현재 상황이라는 특수상황에서는 이런 일반적인 것들을 적용하기 힘들다. 간단하게 보면 boolean형 타입으로 전역변수 설정 후 무한루프를 돌고 플래그로 전역변수를 두는 상황이다.

```
#include <stdio.h>

typedef enum
{
  false,
  true
} boolean;

extern boolean lock = false;

extern int balance;

void main() {
  while (lock == true);
  lock = true;
  balance = balance + 10; // 임계구역
  lock = false;
}
```

boolean type은 integer형으로 하드웨어 수준에서 CPU가 lock을 걸어준다. 그래서 동기화 걱정은 신경 안써도 되고 코드로 볼 때 lock이라는 전역변수로 true, false로 임계구역 lock, unlock을 구현함으로 임계구역을 해결한다. 하지만 실제 특수상황을 봐보자.

C/C++에서 주소록 예제를 보았을 때 주소록을 Single Linked List 자료구조로 이루어져 있다고 볼 때 이런 자료구조는 전역형태로 구현이 된다. 그래서 보통 head 같은 것이 전역으로 선언이 되는데 어떤 문제가 발생할까?

프로그래밍 설계를 할때 UI적인 것과 service 로직을 나누는 것이 일반적인데 UI부분에서 어느 데이터를 조회 혹은 추가 혹은 수정 혹은 삭제를 하는 데 있어서 전역 리스트에 무조건 접근하게 되어있다. 그리고 서비스 부분은 DB와 연결되어 있다고 하면 DB에 접근해 데이터를 가져와야 하는데 그럼 여기서 나오는 게 socket이고 socket이 나오면 N/W I/O는 기본적으로 비동기 처리를 한다. 그러면 UI부분과 서비스 부분을 각각의 스레드로 처리한다고 하면 이 둘은 동시성을 가진다. 왜냐하면 UI에 동기화버튼이 있어서 DB의 데이터를 select 해서 리스트에 반영해야 하고 삭제를 누르면 삭제요청이 서비스 쪽으로 날아가야 하므로 이 둘은 동시성을 가질 수밖에 없다. 여기서 문제는 만약에 데이터를 추가하는 동안 다른 곳에서 추가를 했다면 간발의 차로 데이터 검색이 온전히 이루어질 수 없을 것이고 더 끔찍한 것은 간발의 차로 어느 한 데이터를 삭제했을 때 그 데이터를 접근하여 검색하려 한다면 프로그램은 죽어버린다.

즉, 임계구역 애기가 나오면 반드시 알아야 할 것이 전역자료구조가 되고 추가+삭제+읽기 예를 들어 전체검색을 하는 동안 추가+삭제가 일어나면 안 된다. 또한 추가하는 동안 삭제도 일어나면 안 된다. 이런 경우를 임계구역이라 할 수 있다. 그러면 무엇을 임계구역이라 할 것인가? 일단 제일 흔한 것은 전역적 자료구조에 대해 동시접근할 때 가장 흔히 발생한다. 만약 DB를 쓴다고 하면 DB자체적으로 동시성을 해결해 줌으로 신경을 안 써도 되지만 그게 아니고 이런 자료구조형태를 직접 구현해야 한다고 하면 자료구조에 대한 접근은 굉장히 위험한 행위이다. 위에서 설명했던 것처럼 메모리 손상을 야기할 수도 있다. 즉 이를 막기 위해 기능적인 단위에 대한 연산을 하나의 단위 화하여 원자성을 부여한다.

또한 결론적으로 이를 막기위한 방법은 모니터방법이다. 스레드든 프로세스든 뭔가 동기화 목표달성을 위해 항상 등장하는 것이 Queue다. Queue가 왜 필요하냐면 어떤 스레드가 하나 있는데 스레드 내부에 하는 어떤 연산이 있을 것이고 그 할 처리를 Queue에 담다 두었다가 하나씩 꺼내서 처리한다. 그전에 해야 할 일을 외부에서 누군가 추가하는 것이다. 그럼 여기서 Queue도 자료구조형태로 이중연결리스트형태이다.

즉, 주소록 예제에서 각각 UI, 서비스 부분에 Queue를 두어서 UI에서 서비스로의 요청은 서비스 Queue에 담아두고 서비스에서 UI쪽은 UI Queue에 담아두고 이 Queue들을 통제해서 스레드를 동기화시키는 방법이 모니터이다.

> 이 포스트는 [널널한 개발자](https://www.inflearn.com/course/%EA%B3%B0%EC%B1%85-%EC%89%BD%EA%B2%8C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard)님의 강의를 듣고 작성한 글입니다.

## 대충 넘어가는 교착상태(DeadLock)

사전에 미리 말하면 저번 포스트에 했던 모니터 구조로 Queue를 구성하여 설계하면 DeadLock은 일어날 일이 없다.

교착상태의 예시로 북한과 미국을 들 수 있는데 북한은 핵을 보유하지만 돈이 없다. 미국은 돈이 많아서 북한한테 '핵 그만 개발하면 돈 줄게'라고 요청을 하지만 북한은 '돈부터 먼저 주면 그만할게'라고 하는 상태가 교착상태이다. 그래서 이런 경우는 진행 혹은 진전이라는 것이 존재하지 않고 이대로 영원히 멈춘 상태이다. 즉, 다음 액션을 취할 수 없는 상태이다. 그런데 여기서 DeadLock이 발생하기 위한 전제조건이 나와있다.

> 1\. 상호배제 : 예시로 화장실 혹은 휴지자원을 점유하고 대기
>
> 2\. 비선점 : 임계구간 처리할 때까지 계속 wait 상태
>
> 3\. 점유와 대기 : 배타적
>
> 4\. 원형대기 : 순환구조

예를 들어보자. 비선점형 상황에 자원이 화장실 혹은 휴지가 있다고 해보자. 어떤 사람이 화장실을 들어가 Lock을 걸고 볼일을 본다고 해보자. 이 볼일을 보는 구간이 임계구간인데 만약 휴지라는 자원이 화장실에 없는 경우에 휴지라는 자원이 있을 때까지 wait상태로 빠진다. 또한, 밖에 화장실이라는 자원을 기다리는 사람이 있는데 그 사람은 휴지가 있다고 해보자. 이런 상황이 DeadLock이다.

즉, 여기서 대전제가 성립이 되는데 휴지든 화장실이든 어떤 주체가 얻을려고 하면 얻을 수 있는데 한번 얻으면 그것에 대해 비선점 형태를 취한다. 즉, 자신의 임계구간 처리가 끝날 때까지 계속 이 형태를 취한다. 그래서 그동안에 wait상태가 되는데 중요한 것은 요소가 2가지라는 것이다. 임계구간에 영향을 주는 요소가 n개가 되면 논리적 복잡도가 생긴다. 그래소 요속 늘수록 안 좋고 이 요소는 최소화하는 것이 바람직하다.

DeadLock은 생각보다 쉽게 발생하지 않는다. DeadLock 발생상황을 생각해서 미리 동기화처리를 잘하면 되고 보통은 초보 개발자한테 벌어지는 일이지 그게 아니라면 쉽게 발생되지 않는다. 어떤 프로세스 내에 자원을 n개의 스레드가 동시에 접근하면 경쟁조건이 발생되고 진입할 때 DeadLock이 발생되기도 한다. 근데 중요한 것은 이 때 스레드는 프로세스 내 속하게 되는데 이때 DeadLock을 해결하는 방법이 스레드를 하나 더 만들어서 다른 스레드 상태를 감시하게 하면 되는 것이다. 감시하는 스레드 상태가 계속 wait상태인지 얼마나 오래되었는지 감시하면 되고 대응은 발생하면 그 wait상태 스레드를 kill 한다. 그리고 다른 스레드로 재시작을 하면 되는데 이때, kill 하기 전에 memory Dump를 떠서 CallStack을 Dump를 해서 무엇 때문에 wait상태가 되었는데 분석, 즉 Stack Tracing을 하면 어느 정도 해결이 가능해진다. wait라는 것은 프로세스 내 스레드들이 wait걸때는 무한정이라는 것이 존재한다. 하지만 프로세스 수준으로 확장하면 다음과 같다.

user-mode-application단에 n개의 프로세스가 있다고 해보자. 하드웨어에는 드라이버가 있고 커널요소도 존재할 것이다. 여기서 중요한 것은 디바이스를 제어하는 디바이스 드라이버가 있는데 이때 디바이스가 프린터라고 해보자. 근데 어느 프로세스가 프린터와 연결하고자 프린터를 추상화한 파일이 있을 텐데 이 프로세스가 open을 했다고 해보자. 즉, open을 했다는 소리는 이 파일에 대해 Lock이 걸린다는 것인데 그러고 나서 파일에 대해 ~write()라는 System Call이 발생하고 프린터에 출력으로 이어진다. 근데 문제는 이 프로세스가 프린터를 100장을 해야하는데 어떤 이유로 50장을 하고 suspend상태가 돼버렸다. 그러면 결국 프린터를 추상화한 파일이 Lock이 걸린 상태가 유지되므로 다른 프로세스는 접근이 안되고 wait상태가 될 것이다. 그럼 OS는 이 상황을 어떻게 할까? OS는 프로세스들을 계속 조사해서 일정시간 응답이 없는 프로세스들은 죽었다고 생각하고 이 프로그램을 죽이겠냐는 alert창을 띄워주고 yes를 누르면 그 프로세스는 죽는다. 그리고 Lock이 걸린 파일은 OS가 강제로 회수하게 된다. 그래서 다른 프로세스들이 진입이 가능해진다. 그래서 OS는 이렇게 자원관리를 해주고 프로세스를 통제해주는 중대한 역할을 해준다. 그리고 wait상태에도 무한대가 아니라 일정시간을 주게 되어있는데 보통 일정시간을 주면 일정시간 \* 일정 횟수 + @만큼 시도하는데 계속 fail이 뜨면 메시징 처리를 하게 된다. 그래서 이런것들을 동기화할 때 kernel Object 중에 Mutex를 쓰는데 이 Mutex를 쓸 때도 보통 시간을 같이 명시한다. 요즘은 OS가 좋아져서 프로그램들이 user-mode에서 동작하다가 죽어버리면 그 자원들을 알아서 회수해 준다.
