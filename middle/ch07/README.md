> 이 포스트는 [감자님 강의](https://www.inflearn.com/course/%EB%B9%84%EC%A0%84%EA%B3%B5%EC%9E%90-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard '인프런 강의')를 기반으로 작성되었습니다.

## 가상메모리 개요

컴퓨터마다 실제 메모리의 크기가 다르다. 만약 운영체제나 프로세스가 4GB 메모리에서 동작하도록 만들어졌다면 이보다 작은 메모리를 가진 컴퓨터에서는 실행을 할 수 없다. 가상메모리에는 이런 문제를 완벽히 해결하였다. 프로세스는 운영체제의 영역이 어디 있는지 혹은 물리 메모리의 크기가 얼마나 큰지 몰라도 된다. 즉, 개발자는 물리 메모리의 크기와 프로세스가 메모리 어느 위치에 올라가는지 신경 쓰지 않고 0x0번지에서 시작된다고 생각하고 개발을 하면 된다. 프로세스는 메모리 관리자를 통해서 메모리에 접근이 가능하다. 프로세스 입장에서는 물리 메모리에 직접 접근할 일이 없고 메모리 관리자에게 요청만 하면 된다. 메모리 관리자는 프로세스의 요청이 있으면 그에 맞는 물리 메모리로 연결시켜 준다. 가상 메모리의 크기는 이론적으로 무한대지만 실제로는 물리 메모리의 크기와 CPU의 bit수로 결정된다. 만약 32bit CPU인 경우 표현할 수 있는 주소 값은 2^32으로 대략 4GB 정도 되고 가상메모리 크기도 4GB이다.

32bit CPU의 경우 최대 메모리 크기가 4GB라고 했는데 운영체제를 포함해서 수많은 프로세스들은 어떻게 실행할까? 4GB를 차지하는 프로세스 5개와 운영체제를 실행한다고 가정하자. 그럼 운영체제를 제외하고도 적어도 20GB가 필요한데 4GB로는 턱없이 부족하다. 이럴 때 가상메모리 시스템은 물리 메모리 내용의 일부를 HDD에 있는 스왑영역으로 옮기고 처리가 필요할 때 물리 메모리로 가져와 실행시키기 때문에 운영체제와 프로세스 5개를 전부 실행이 가능하다.

메모리 관리자는 물리 메모리와 스왑영역을 합쳐서 프로세스가 사용하는 가상주소를 물리주소로 변환하는데 이것을 동적주소변환이라고 한다. 이 가상주소는 메모리나 스왑영역에 저장한다. 동적주소변환을 거치면 프로세스는 마음대로 사용자 데이터를 물리 메모리에 배치할 수 있다. 메모리 관리자는 "물리 메모리를 어떻게 나눌지", "프로세스를 어디다 배치할지", "부족한 물리 메모리는 어떻게 처리할지"와 같은 문제를 처리해야 하기 때문에 복잡한 과정을 거친다. 실제 물리주소 0x0번지는 운영체제 영역이므로 프로세스가 사용하지 못한다. 가상메모리 시스템에서는 운영체제 영역을 제외한 나머지 영역을 일정한 크기로 나우어서 프로세스에게 할당하는데 할당하는 방식은 메모리 분할방식과 마찬기지로 가변분할방식과 고정분할방식으로 나뉜다.

가상메모리 시스템에서 가변분할방식을 이용한 세그멘테이션, 고정분할방식을 이용한 페이징이라는 것이 있다. 세그멘테이션에는 외부단편화와 같은 단점이 있고 페이징에서는 내부단편화와 같은 단점이 있기 때문에 이 단점을 보완한 세그멘테이션-페이징 혼용기법을 사용한다. 가상메모리 시스템에서 가상주소는 메모리나 스왑영역 한 곳중에 위치하는데 메모리 관리자는 가상주소와 물리주소를 1:1 매핑 테이블로 관리한다. 매핑 테이블을 보면 프로세스가 세그먼트 n에 위치하는지 혹은 스왑영역에 저장하는지 알 수 있다.

> 이 포스트는 [감자님 강의](https://www.inflearn.com/course/%EB%B9%84%EC%A0%84%EA%B3%B5%EC%9E%90-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard '인프런 강의')를 기반으로 작성되었습니다.

## 세그멘테이션(배치정책)

가변분할 방식을 이용한 세그멘테이션 기법을 보자. 세그멘테이션에서 프로그램은 함수나 모듈등으로 세그먼트를 구성한다. 프로세스 입장에서 메모리를 살펴보면 메인코드가 있는 세그먼트, 전역 데이터들이 있는 세그먼트, 힙영역이 있는 세그먼트, 스택영역이 있는 세그먼트 등이 있다. 각 세그먼트들은 서로 인접할 필요가 없다. 반면 프로세스 입장에서는 우리가 앞서 봤던 것처럼 코드영역, 데이터영역, 힙영역, 스택영역을 서로 인접한 것처럼 바라본다.

시용자와 프로세스, CPU가 바라보는 주소는 논리주소라고 한다. 실제 물리주소 변환은 중간에 메모리 관리자(MMU)가 해준다. 그럼 메모리 관리자는 어떻게 논리주소를 물리주소로 변환할까? 메모리 관리자는 세그멘테이션 테이블이라는 것을 가지고 있다. 세그멘테이션 테이블에는 Base Address와 Bound Address정보가 저장되어 있고 이걸 이용하여 물리 메모리 주소를 계산한다. CPU에서 논리주소를 전달해주면 메모리 관리자는 이 논리주소가 몇 번 세그먼트인지 알아낸다. 그리고 메모리 관리자 내에 Segment Table Base Register를 이용해서 물리 메모리 내에 있는 세그멘테이션 테이블을 찾고 세그먼트 번호를 인덱스로 Base Address와 Bound Address를 찾는다.

> 운영체제는 컨텍스트 스위칭을 할 때마다 메모리 관리자 내에 Segment Table Base Register를 해당 프로세스의 것으로 값을 바꿔줘야 한다. 컨텍스트 스위칭은 이런 작업까지 하기 때문에 굉장히 무거운 동작이다.

Bound Address는 세그먼트의 크기를 나타낸다. 메모리 관리자는 CPU에서 받은 논리주소와 Bound Address의 크기를 비교한다. 만약 논리주소가 Bound Address보다 작다면 논리주소와 Base Address를 더하여 물리주소를 구하고 논리주소가 Bound Address보다 크다면 메모리를 침범했다고 생각하고 에러를 발생시킨다.

그럼 예시로 논리주소를 물리주소로 변환하는 걸 두가지만 살펴보자. 첫 번째로 CPU에서 세그먼트 1번이 0x632번지로 접근한다고 가정하자. 메모리 관리자는 CPU 요청을 받고 세그먼트 1번인 것을 알아낸다. 그리고 메모리 관리자 내에 있는 Segment Table Base Register를 이용해서 세그멘테이션 테이블을 찾는다. 세그멘테이션 테이블을 찾은 다음 세그먼트 1번이 위치한 1번 인덱스를 참조한다. 논리주소 632와 Bound Address를 비교하니 만약 논리주소가 더 작다면 이 632와 Base Address(ex. 5000)를 더하여 5632가 나온다. 최종적으로 논리주소 0x632번지는 물리주소 0x5632번지로 성공적으로 변환하였다.

두 번째 예시로 세그먼트 3번이 0x750번지로 접근한다고 가정하자. 메모리 관리자는 CPU의 요청을 받고 세그먼트 3번인 것을 알아낸다. 그리고 Segment Table Base Register를 이용해 세그멘테이션 테이블을 찾아 3번 인덱스를 참조한다. 논리주소 750과 Bound Address를 비교하니 논리주소가 더 크다고 하자. 그러면 메모리 관리자는 메모리를 침범했다고 판단하고 인터럽트를 발생시켜 프로세스를 종료시킨다.

세그멘테이션의 장접은 메모리를 가변적으로 분할할 수 있고 코드영역, 데이터영역, 스택영역, 힙영역을 모두 처리할 수 있기 때문에 공유와 각 영역에 대한 메모리 접근보호가 편리하고 관리가 쉽다. 하지만 단점으로 가변분할방식의 단점인 "외부 단편화"가 발생한다.

> 이 포스트는 [감자님 강의](https://www.inflearn.com/course/%EB%B9%84%EC%A0%84%EA%B3%B5%EC%9E%90-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard '인프런 강의')를 기반으로 작성되었습니다.

## 페이징

이번 포스트에서 고정분할방식을 이용한 페이징에 대해 알아보자. 세그멘테이션 기법은 외부단편화 문제가 있기 때문에 이를 해결하기 위해 고안되었다.(조각모음은 오버헤드가 너무 큼) 페이징은 메모리를 할당할 때 정해진 크기의 페이지로 나눈다. 모든 페이지는 크기가 같기 때문에 관리가 굉장히 쉽다. 또한 일정한 크기로 나눴기 때문에 외부단편화 현상이 일어나지 않는다. 대신 내부단편화가 발생한다.

논리주소공간과 물리주소공간이 있다고 하자. 논리주소공간은 사용자와 프로세스가 바라보는 주소공간이고 물리주소공간은 실제 메모리에서 사용되는 주소공간이다. 페이징에서 논리주소공간은 일정한 크기로 균일하게 나눈다. 이것을 페이지라고 부른다. 물리주소공간도 페이지의 크기와 동일하게 나누는데 이것을 프레임이라고 부른다.

그럼 페이징의 주소변환을 어떻게 하는지 알아보자. 세그멘테이션과 마찬가지로 메모리 관리자는 테이블을 가지고 있는데 이를 페이지 테이블이라고 부른다. CPU에서 논리주소를 전달해 주면 메모리 관리자는 이 논리주소가 몇 번 페이지인지 오프셋은 얼마인지 알아낸다. 그리고 메모리 관리자 내에 Page Table Base Register를 이용해서 물리 메모리에 있는 페이지 테이블을 찾고 페이지 번호를 인덱스로 프레임 번호를 알아내고 오프셋을 이용해 물리주소 변환을 한다. 페이지 테이블에 invalid라고 표시되어 있으면 스왑영역, HDD에 저장되었다는 의미이다.

> 세그멘테이션과 마찬가지로 Page Table Base Register는 운영체제가 컨텍스트 스위칭을 할 때마다 해당 프로세스의 것으로 업데이트를 해줘야 한다.

그럼 32bit CPU가 어떻게 주소변환을 하는지 알아보자. 32bit CPU에서 가상 메모리 크기는 약 4GB이다. 이 4GB의 가상메모리를 크기가 2^24, 약 16MB인 페이지로 나눠보자. 그럼 32bit 중에 24bit는 페이지의 크기를 나타내고 나머지 8bit는 페이지 번호를 나타낸다. 페이지 번호는 2^8이니까 총 256개 페이지가 존재하게 된다. 이렇게 나눴으면 4GB 메모리가 16MB의 페이지 256개로 나뉘게 된 것이다. 그러면 페이지 0 은 0~16777216번지, 페이지 1은 16777217~33554432번지, 페이지 255는 4278190081~4294967296번지로 구성되어 있다. 이제 물리주소의 프레임도 가상주소의 페이지의 크기와 동일하게 16MB로 나누자. 물리주소(2GB)는 프레임 128개로 구성된다. 이렇게 예시를 든 이유는 물리주소의 크기가 가상주소의 크기보다 작아도 문제가 없다는 것을 보여주기 위해서 이렇게 예시를 든 것이다. 부족한 물리메모리는 스왑처리를 하기 때문에 괜찮다. 메모리 관리자 내에 페이지 테이블은 1차원 배열로 구성되어 있는데 페이지 번호가 배열의 인덱스가 된다. 해당 인덱스로 가면 프레임을 얻을 수 있다. 이제 여기서 CPU가 논리주소 0x1000번지에 접근하다고 가정하자. 논리주소 0x1000번지의 물리주소를 구해보자. 그럼 일단 페이지 번호와 오프셋값을 구해야 한다. 구하는 공식은 아래와 같다.

> 페이지 번호: 논리주소 / 페이지 크기  
> 오프셋: 논리주소 % 페이지 크기

그러면 위의 공식을 적용하면 페이지 번호는 0이고 오프셋은 1000이 나온다. 그러면 페이지 번호와 오프셋을 구했으니 페이지 넘버를 페이지 테이블 인덱스로 참조한다. 0번 인덱스의 프레임 번호가 3이라고 한다면 프레임 3번 위치에 오프셋 1000만큼 더하면 물리주소 변환이 완료된다. 두 번째 예시를 들어보자. CPU가 논리주소 0x31554432번지에 접근한다고 가정하자. 그럼 페이지 번호를 구해야 한다. 공식에 대입하면 페이지 번호는 1이 나온다. 이제 오프셋을 구해보자. 오프셋을 구하면 1477216이 나온다. 페이지 넘버와 오프셋을 구했으니 페이지 번호를 페이지 테이블의 인덱스로 참조한다. 즉, 1번 인덱스를 참조하여 프레임을 구한다. 프레임이 1이라고 가정한다면 이 프레임 1 위치에서 1477216을 더해주면 물리주소 변환이 완료된다.

여기까지 보면 세그멘테이션과 페이징은 굉장히 비슷해 보인다. 이 둘의 차이는 무엇일까? 바로 페이지의 크기이다. 세그멘테이션은 프로세스마다 크기가 달라 Bound Address를 가지고 있지만 페이징은 모든 페이지의 크기가 동일해서 크기를 표현하는 Bound Address는 필요하지 않다. 페이징은 이러한 특징 때문에 외부단편화는 발생하지 않지만 내부단편화는 발생한다. 정해진 크기의 페이징보다 프로세스의 정보가 작으면 그만큼 공간이 낭비되는데 이를 내부단편화라고 한다. 하지만 세그멘테이션의 단점과 비교하면 많은 공간이 낭비되는 것이 아니라 심각하게 생각을 안 해도 괜찮다. 또 다른 차이는 무엇일까? 이것도 페이지의 크기 때문에 생긴 차이인데 세그멘테이션은 논리적인 영역별로 세그먼트를 나눈다. 세그먼트마다 크기를 다르게 나눌 수 있으니 코드영역, 데이터영역, 스택영역, 힙영역을 나눌 수 있다. 하지만 페이징은 페이지의 크기가 고정되어 있어서 논리적인 영역별로 나누는 것이 아니라 페이지로 나누기 때문에 논리적인 영역을 나눌 수 없다. 그래서 특정 영역만 딱 떼어내서 공유하거나 권한을 부여하기 힘들다. 또한 페이징의 가장 신경 써야 하는 것은 페이지 테이블의 크기이다. 각 프로세스마다 페이지 테이블을 가지고 있는데 프로세스가 많아질수록 페이지 테이블도 많아지기 때문에 프로세스가 실제로 사용할 수 있는 메모리 영역이 줄어든다. 실제로 메모리 관리자가 참조하는 페이지 테이블도 물리 메모리의 운영체제 영역에 저장되어 있기 때문에 페이지 테이블 크기가 너무 크면 사용자 영역이 부족하다. 이 때문에 페이지 테이블 크기를 적절히 유지하는 게 중요하다.

> 이 포스트는 [감자님 강의](https://www.inflearn.com/course/%EB%B9%84%EC%A0%84%EA%B3%B5%EC%9E%90-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard '인프런 강의')를 기반으로 작성되었습니다.

## 페이지드 세그멘테이션

이번 포스트에서 페이지드 세그멘테이션 기법을 살펴보자. 페이지드 세그멘테이션은 세그멘테이션과 페이징을 혼합해 장점을 취한 방식이다.(새로운 단점도 생김) 세그멘테이션은 가변분할방식이라서 코드영역, 데이터영역, 스택영역, 힙영역을 세그먼트로 나눠서 관리할 수 있다. 때문에 다른 프로세스와 공유하기도 편하고(ex. 코드영역만 떼어서 공유가능) 각 영역에 대한 메모리 접근보호를 하기가 쉽다.(ex. 코드영역의 권한을 x로 설정) 페이징은 고정분할방식으로 메모리를 효율적으로 관리할 수 있다.(오버헤드가 적음)

그럼 메모리 접근권한에 대해 살펴보자. 메모리 접근권한은 메모리의 특정번지에 부여된 권한으로 읽기, 쓰기, 실행 3가지가 있다. 프로세스는 코드영역, 데이터 영역, 스택영역, 힙영역이 있는데 각 영역마다 접근권한이 존재한다. 코드영역은 프로그램 그 자체이므로 수정되면 안 되기 때문에 읽기와 실행권한만 존재한다. 데이터영역은 일반변수, 전역변수, 상수로 선언한 변수가 저장되기 때문에 읽기 권한이 있고 쓰기 권한은 있거나 없거나이다. 당연히 실행권한은 존재하지 않는다. 스택과 힙영역은 읽기, 쓰기 권한이 있고 실행권한은 존재하지 않는다. 메모리 접근권한에 대한 검사는 가상주소에서 물리주소로 변환될 때마다 일어나는데 만약 권한을 위반했으면 에러를 발생시킨다.

이제 페이지드 세그멘테이션에 대해 알아보자. 세그멘테이션 기법에서 세그멘테이션 테이블은 Base Address와 Bound Address로 구성된다. 페이징 기법에서 페이지 테이블은 프레임 번호로 구성된다. 이제 이 둘을 혼합하여 페이지드 세그멘테이션으로 만들어보자. 페이지드 세그멘테이션 기법에서는 세그멘테이션 테이블에 권한비트를 추가한다. 그리고 Base Address는 페이지 번호로 변경되고 Bound Address는 이 세그먼트의 페이지 개수로 변경된다. 각각의 역할은 이름만 달라졌을 뿐 본질적으로 달라진 것은 없다. 만약 가상주소가 들어오면 먼저 가상주소를 이용해 몇 번 세그먼트인지 알아낸다. 그리고 해당 세그먼트가 메모리 접근 권한을 위반하는지 검사한다. 접근권한을 위반했으면 프로세스를 종료시키고 위반하지 않았다면 페이지 숫자와 페이지 개수를 가져온다. 이제 페이지 숫자로 페이지 테이블에 접근해서 프레임 번호를 가져오고 물리 메모리 내에 해당 프레임에 접근해서 그 위치에 페이지 개수를 더하여 물리주소를 구한다. 만약 물리 메모리에 해당 프레임이 없다면 스왑영역에 물리 메모리를 가져온다. 페이지드 세그멘테이션의 단점은 물리 메모리에 접근하기 위해서 메모리에 접근을 두 번 해야 하는 것이다. 첫 번째 세그멘테이션 테이블을 참조할 때, 두 번째는 페이지 테이블을 참조할 때 일어난다. 이런 단점 때문에 현대 운영체제는 페이징과 페이지드 세그멘테이션 기법을 적절히 섞어서 사용한다.

> 이 포스트는 [감자님 강의](https://www.inflearn.com/course/%EB%B9%84%EC%A0%84%EA%B3%B5%EC%9E%90-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard '인프런 강의')를 기반으로 작성되었습니다.

## 디멘드 페이징

우리는 프로세스가 실행될 때 프로세스를 이루고 있는 코드영역, 데이터영역, 스택영역, 힙영역과 같은 모듈이 모두 메모리에 올라와 실행된다고 알고 있다. 하지만 실제로는 모든 모듈이 메모리에 올라오는 것이 아니라 필요한 모듈만 올라와서 실행된다. 이게 어떻게 가능할까?

컴퓨터 과학자 도널드 커누스는 90:10이라는 법칙을 발견했다. 프로그램이 실행될 때 90%의 시간이 10%의 코드에서 보내는 것을 의미한다. 이것을 지역성 이론이라고 말하는데 지역성은 2가지가 존재한다. 첫 번째, 공간의 지역성으로 현재 위치에서 가까운 데이터에 접근할 확률이 높아진다는 것이다. 둘째, 시간의 지역성으로 현재 기준으로 가까운 시간에 접근했던 데이터가 먼 시간에 접근했던 데이터보다 접근할 확률이 높다는 것이다. 프로그램을 작성할 때 goto문은 되도록 사용하지 말라고 하는데 이는 코드의 구조파악이 어려운 것도 있지만 지역성 이론에 따라 성능에 좋지 않기 때문이다. (goto문은 지역성 이론을 위배하기 때문에 꼭 필요한 상황에서만 사용하는 것을 권장한다.) 지역성 이론은 조만간 쓰일 데이터만 메모리에 올리고 당분간 필요하지 않을 것 같은 데이터는 스왑영역으로 보내 성능을 향상한다.

디멘드 페이징은 조만간 필요할 것 같은 데이터를 메모리로 가져오고 쓰이지 않을 것 같은 데이터는 스왑영역으로 이동시키는 정책이다. (지역성 이론을 구현한 정책) 포토샵을 예시로 들어보자. 포토샵과 같은 프로그램은 본 프로그램 외에도 이미지에 효과를 주는 외부필터들이 있다. 이 필터들은 포토샵과 같이 메모리에 모두 올리면 메모리를 많이 차지해 프로그램이 무거워진다. 그래서 본 프로그램만 메모리에 올리고 외부필터들은 사용자의 요청이 있을 때만 메모리로 가져오는 것이 메모리도 절약되고 메모리를 효율적으로 관리할 수 있고 프로세스의 응답속도도 빨라진다.

여기서 잠깐 메모리 구조에 대해 살펴보자. 메모리는 레지스터, 캐시, 메인 메모리, 보조저장장치로 나눌 수 있다. 레지스터는 CPU내에 존재하고 CPU의 한 사이클에 접근할 수 있어서 굉장히 빠르다. 캐시는 CPU의 수 사이클에서 수십 사이클에 접근 할 수 있고 메인 메모리는 수백 사이클이 걸린다. 반면에 보조저장장치에는 수백만 사이클이 걸려 굉장히 오래 걸린다. 우리가 현실세계에서 상자를 가지러 간다고 생각할 때 레지스터는 같은 방에 있는 상자를 가지러 가는 것이고, 캐시는 같은 건물에 있는 상자를 가지러 가는 것이고, 메인 메모리는 같은 동네에 있는 상자를 가지러 가는 것이다. 보조저장장치 같은 경우 상자를 가지러 우주로 가는 것과 같다. 이처럼 메모리에 접근하는 시간이 보조저장장치 쪽으로 갈수록 느려진다. 디멘드 페이징은 스왑영역을 보조저장장치에 저장하는데 성능 향상을 위해서 스왑영역으로 데이터를 이동시키는 것을 최소화시켜야 한다. 가상 메모리의 크기는 물리 메모리에 스왑영역을 합친 것이다. 스왑 영역에서 물리 메모리로 데이터를 가져오는 것을 스왑 인이라고 부르고 물리 메모리에서 스왑영역으로 데이터를 보내는 것을 스왑 아웃이라고 부른다.

가상주소가 주어지면 메모리 관리자는 페이지 테이블을 참조해서 물리 메모리가 있는 프렘을 알아내거나 스왑영역의 위치를 알아내는데 이를 위해 페이지 테이블에 여러 가지 비트가 존재한다.

> 페이지 테이블을 이루고 있는 한 행을 페이지 테이블 엔트리(PTE)라고 부른다.

이전 페이징 포스트에서 페이지 테이블 엔트리는 프레임 숫자로 구성되어 있다고 했는데 실제로는 더 많은 비트들이 존재한다. 바로 접근비트, 변경비트, 유효비트, 권한비트가 존재한다. 접근비트는 페이지가 메모리에 올라온 후 데이터에 접근이 있었는지 알려주는 비트이다. 메모리에 읽거나 실행작업을 했다면 1로 변경된다. 변경비트는 페이지가 메모리에 올라온 후 데이터의 변경이 있었는지 알려주는 비트이다. 메모리에 쓰기 작업을 했으면 1로 변경된다. 유효비트는 페이지가 물리메모리에 있는지 알려주는 비트이다. 만약 유효비트가 1이라면 페이지가 스왑영역에 있는 것이고 0이라면 물리메모리에 있다는 의미이다. 읽기, 쓰기, 실행 비트는 권한비트로 해당 메모리에 접근권한이 있는지 검사하는 비트이다. 프로세스가 가상메모리에 접근요청을 했을 때 메모리 관리자는 페이지 테이블을 보고 물리 메모리의 프레임을 찾아내는데 만약 물리 메모리에 없다면 page fault라는 인터럽트를 발생시킨다. page fault가 발생하면 보조저장장치의 스왑영역에 접근하게 되고 해당 프로세스는 대기상태가 된다. 그럼 스왑영역에 있는 데이터가 메모리로 올라가는 작업을 시작하고 메모리로 올라왔다면 대기상태에 있던 프로세스는 다시 실행상태가 된다.

그럼 3가지 상황에서 가상메모리 주소가 어떻게 물리메모리와 스왑영역에서 참조되는지 알아보자.  첫 번째 상황은 스왑이 필요 없는 경우이다. 프로세스가 페이지 0을 요청했다고 가정하자. 페이지 테이블의 0번 인덱스는 유효비트가 0이고 프레임 숫자가 1이라고 하자. 이 말은 해당 주소가 물리메모리의 1번 프레임에 존재한다는 뜻이다. 그럼 물리메모리에 있는 1번 프레임에 접근해 데이터를 참조한다. 두 번째 상황은 스왑영역에 있는 데이터를 참조하는 경우이다. 프로세스가 페이지 2번을 요청했다고 가정하자. 페이지 테이블의 2번 인덱스를 보니 유효비트가 1이고 프레임 숫자가 2라고 하자. 이 말은 페이지가 스왑영역 2번에 있다는 것이다. 그럼 물리 메모리에 적절히 빈 공간을 찾는다. 그래서 스왑영역 2번에 저장된 데이터를 물리메모리에 옮기고 페이지 테이블에 해당 엔트리의 유효비트를 0으로 프레임 숫자를 옮긴 프레임의 숫자로 기입해 준다. 그리고 프로세스에게 데이터를 참조하게 해준다. 세번째 상황은 물리메모리가 꽉 찼을 때 스왑영역에 있는 데이터를 참조하는 경우이다. 프로세스가 페이지 1번을 요청했다고 가정하자. 페이지 테이블 1번 인덱스를 보면 유효비트가 1이고 프레임 숫자가 0이라고 하자. 이 말은 페이지가 스왑영역 0번에 있다는 뜻이다. 물리메모리로 가져오기 위해 적절히 빈 공간을 찾지만 꽉 차서 여유가 없다. 그럼 현재 물리메모리에서 필요하지 않다고 판단되는 영역을 스왑영역으로 옮긴다. 그리고 스왑영역에 있던 프레임을 물리메모리로 가져온다. 그리고 프로세스에게 데이터를 참조하게 해준다.

스왑영역에서 물리메모리로 가져오는 스왑 인과 물리메모리에서 스왑영역으로 보내는 스왑 아웃을 할 때 어떤 게 적절한지는 운영체제가 판단한다. 이 판단하는 것을 페이지 교체 알고리즘이라고 부른다.

> 이 포스트는 [감자님 강의](https://www.inflearn.com/course/%EB%B9%84%EC%A0%84%EA%B3%B5%EC%9E%90-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard '인프런 강의')를 기반으로 작성되었습니다.

## 페이지 교체정책

이전 포스트들에서 세그멘테이션, 페이징, 페이지드 세그멘테이션으로 메모리 배치정책을 알아봤다. 또한 디멘드 페이징으로 메모리에서 가져오기 정책을 알아봤다. 이번 포스트에서 메모리가 꽉 찼을 때 어떤 페이지를 스왑영역으로 보낼지 결정하는 페이지 교체정책을 알아보자. 프로세스는 데이터 접근을 위해 메모리를 참조하는데 해당 데이터가 메모리에 없으면 page fault가 발생한다. page fault가 발생하면 해당 페이지를 스왑영역에서 메모리로 불러들여야 하는데 메모리가 꽉 차서 공간이 없다면 메모리에 있는 페이지 중 하나를 선택해서 스왑영역으로 옮겨야 한다. 메모리에 있는 페이지를 스왑영역으로 옮길 때 어떤 페이지를 선택할지 결정하는 정책을 페이지 교체정책이라고 부른다. 페이지 교체정책에는 여러 가지가 존재한다. 한번 살펴보자.

### Ramdom

첫번째 방법은 무작위로 선택하는 방법이다. 이 방법은 지역성을 고려하지 않기 때문에 자주 사용되는 페이지가 선택될 때도 있어 성능이 별로 좋지 않아 거의 사용을 하지 않는다.

### FIFO

두 번째 방법은 메모리에 들어온 지 가장 오래된 페이지를 선택하는 방법이다. 마트에서 계산하려고 줄을 기다릴 때 FIFO와 같은 알고리즘이 공평하지만 페이지 교체정책에서는 자주 쓰이는 페이지가 먼저 들어왔다는 이유로 해당 페이지가 교체되면 공평하지 않을 것이다. 이런 단점도 존재하지만 구현이 간단하고 성능도 괜찮아 조금 변형해서 많이 사용한다.

### Optimum

세번째 방법은 앞으로 가장 오랫동안 쓰이지 않을 페이지를 선택하는 방법이다. 이 방법은 사실상 구현이 불가능한 이론적인 선택방법이다. 구현이 불가능해서 필요가 없을 것 같지만 다른 알고리즘과 성능비교를 할 때 참조용으로 많이 쓰인다.

### LRU

네 번째 방법은 최근에 가장 사용이 적은 페이지를 선택하는 방법이다. 지역성 이론의 시간의 지역성에 따르면 최근 사용한 데이터가 앞으로도 사용될 확률이 높기 때문에 최근에 가장 사용을 적게 한 페이지가 앞으로도 사용될 확률이 적다는 결론이 나온다. 실제로도 Optimum 알고리즘에 근접한 성능을 보인다. 하지만 프로그램이 지역성을 띄지 않을 대는 성능이 떨어진다. 페이지 테이블 엔트리는 여러 개의 비트와 페이지 넘버가 저장된다고 했는데 이곳에 시간을 기록하려면 비트가 많이 필요하게 된다. 하지만 많은 비트를 준비하기는 어려우니 실제 LRU를 구현할 때는 접근비트를 이용해서 LRU에 근접하게 구현한다.

### 예시

그러면 Optimum과 FIFO, LRU가 페이지 교체를 하는 상황을 비교해보자.

| Optimum(page fault: 0) |     |     | FIFO(page fault: 0) |     |     | LRU(page fault: 0) |     |     |
| ---------------------- | --- | --- | ------------------- | --- | --- | ------------------ | --- | --- |
|                        |     |     |                     |     |     |                    |     |     |

> A -> B -> C -> A -> C -> D -> A -> D -> C -> A -> B

페이지가 위의 순서대로 요청된다고 가정하자. Optimum과 FIFO, LRU 전부 메모리가 비어있기 때문에 처음 A, B, C 요청에선 전부 page fault가 발생한다.

| Optimum(page fault: 3) |     |     | FIFO(page fault: 3) |     |     | LRU(page fault: 3) |     |     |
| ---------------------- | --- | --- | ------------------- | --- | --- | ------------------ | --- | --- |
| A                      | B   | C   | A                   | B   | C   | A                  | B   | C   |

> A -> C -> D -> A -> D -> C -> A -> B

메모리에 A, B, C가 들어온 상태에서 페이지 A요청이 들어온다. Optimum, FIFO, LRU 전부 A가 존재하기 때문에 page fault가 발생하지 않는다. 이어서 C 요청이 들어오는데 Optimum, FIFO, LRU 전부 C가 존재하기 때문에 page fault가 발생하지 않는다.

| Optimum(page fault: 3) |     |     | FIFO(page fault: 3) |     |     | LRU(page fault: 3) |     |     |
| ---------------------- | --- | --- | ------------------- | --- | --- | ------------------ | --- | --- |
| A                      | B   | C   | A                   | B   | C   | A                  | B   | C   |

> D -> A -> D -> C -> A -> B

이제 페이지 D의 요청이 들어오는데 여기서 page fault가 발생한다. Optimum은 이후에 어떤 요청이 있는지 미리 알기 때문에 뒤를 훑어 본다. B가 가장 사용되지 않을 것을 알고 있기 때문에 페이지 B를 스왑영역으로 옮기고 B가 있던 자리에 D를 가져온다. FIFO는 먼저 들어온 페이지가 먼저 나가기 때문에 가정 먼저 들어온 페이지 A를 스왑영역으로 보내고 A가 있던 자리에 D를 가져온다. LRU는 최근에 가장 사용이 적은 페이지가 나가기 때문에 최근에 들어온 페이지의 참조 수를 계산한다. 이 예시에서는 B가 가장 덜 사용되었으니 B를 스왑영역으로 옮기고 B가 있던 자리에 D가 들어온다.

| Optimum(page fault: 4) |     |     | FIFO(page fault: 4) |     |     | LRU(page fault: 4) |     |     |
| ---------------------- | --- | --- | ------------------- | --- | --- | ------------------ | --- | --- |
| A                      | D   | C   | D                   | B   | C   | A                  | D   | C   |

> A -> D -> C -> A -> B

이런 식으로 나머지 페이지들이 들어오면 각각의 정책에 맞게 페이지 교체가 된다. 최종 계산을 해보면 page fault 수가 LRU와 Optimum이 5번으로 굉장히 비슷하게 동작했고 FIFO는 6번으로 성능이 가장 안 좋다. 지금까지 내용을 보면 무조건 LRU를 사용하는 것이 좋을 것 같다. 실제로 FIFO는 자주 사용되는 페이지도 교체되기 때문에 성능이 떨어진다. FIFO의 가장 큰 문제는 빌레이디라는 사람이 제시한 빌레이디의 역설이다. 빌레이디의 역설이란 page fault를 줄이려고 메모리를 더 늘려서 프레임수를 늘렸는데 오히려 page fault가 더 많이 발생하는 현상을 말한다. 빌레이디의 역설은 FIFO에서만 발생하며 LRU에서는 발생하지 않는다. 그럼 LRU가 좋다는 것이 분명해졌으니 LRU를 구현해야 하는데 시간을 기록해야 하는 LRU는 구현이 너무 힘들다. 왜냐하면 시간을 기록한 bit가 많이 필요할 뿐만 아니라 많은 bit가 있어도 시간이 아주 오래 지난다고 가정하면 어쩔 수 없이 오버플로우가 발생하게 된다. 그럼 아주 시간이 오래 지나면 오버플로우가 발생하고 값이 초기화되면서 시간을 올바르게 표현할 수 없다.

### 클락 알고리즘

이 때문에 LRU와 유사하게 구현하는 방법을 고안했는데 이를 클락 알고리즘이라고 한다. 클락 알고리즘은 접근 비트 1개를 이용한다. 일정시간 간격마다 모든 페이지의 접근비트를 0으로 초기화한다. 접근비트의 초기값은 0으로 설정되어 있고 만약 페이지가 참조되었다면 1로 변경한다. 그럼 일정 시간 간격마다 페이지가 참조되었는지 참조되지 않았는지 확인이 가능하다. 클락 알고리즘은 페이지를 원형으로 연결되어 있다. 스왑영역으로 옮길 페이지를 포인터로 가리키는데 이 포인터를 클락 핸드라고 부른다. 클락 핸드는 시계방향으로 돈다. 만약 page fault가 발생해서 스왑영역으로 보내야 하는 상황이 온다면 클락 핸드는 현재 참조하고 있는 페이지의 접근 비트를 확인한다. 만약 접근 비트가 1이라면 해당 접근 비트를 0으로 변경하고 클락 핸드가 다음 페이지를 가리킨다. 이렇게 반복하다가 접근 비트가 0인 페이지를 발견하면 해당 페이지를 스왑영역으로 보낸다.

### 향상된 클락 알고리즘

향상된 클락 알고리즘이라는 것도 있는데 이 알고리즘은 접근비트만 이용하는 것이 아니라 변경비트까지 본다. 스왑영역으로 보내지는 가장 순위가 높은 것은 접근비트가 0이고 변경비트도 0인 페이지다. 그다음으로 접근비트가 0, 변경비트가 1인 페이지고 그 다음으로 접근비트가 1, 변경비트가 0인 페이지고 마지막으로 접근비트가 1, 변경비트가 1인 페이지가 교체된다.

### 2차 기회 페이지 교체 알고리즘

이렇게만 보면 LRU만 사용하고 FIFO는 사용할 일이 없어 보인다. 하지만 부득이하게도 FIFO를 사용할 경우가 있다. LRU에선 접근비트를 이용하는데 하드웨어적으로 접근비트를 지원하지 않는 시스템에서는 FIFO를 이용할 수밖에 없다. 어쩔 수 없이 FIFO를 이용하는 상황이 나오기 때문에 FIFO의 성능을 높이기 위한 방법을 고안했다. FIFO의 장점으로는 구현이 간단하다는 것인데 자주 사용하는 페이지가 교체될 수 있다는 단점이 있다. 이를 위해 2차 기회 페이지 교체 알고리즘을 고안했는데 FIFO 방식에서 자주 사용되는 페이지에게는 또 한 번의 기회를 주는 것이다. FIFO 방식과 동일하게 동작하지만 만약 page fault 없이 페이지 접근에 성공하면 해당 페이지를 큐의 맨 뒤로 보내는 것이다. 이 알고리즘의 성능은 LRU보단 좋지 않고 FIFO보단 좋다.

> 이 포스트는 [감자님 강의](https://www.inflearn.com/course/%EB%B9%84%EC%A0%84%EA%B3%B5%EC%9E%90-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard '인프런 강의')를 기반으로 작성되었습니다.

## 스레싱과 워킹셋

이번 포스트에서 스레싱과 워킹셋을 알아보자. 우리는 CPU 스케줄링을 알아봤는데 CPU 스케줄링의 목표는 CPU 사용률을 높이는 것이다. CPU 사용률을 높이기 위해서 동시에 실행하는 프로세스의 수 즉, 멀티프로그래밍 정도를 올리는 것이다. 동시에 실행하는 프로세스의 수가 늘어나면 어떤 프로세스가 I/O 작업으로 CPU를 사용할 수 없을 때 다른 프로세스로 컨텍스트 스위칭을 해서 CPU 사용률을 높일 수 있다. CPU 사용률을 높이기 위해 멀티프로그래밍 정도를 늘렸다면 당연히 이 프로세스들이 필요로 하는 공간이 있기 때문에 물리메모리에 프레임을 할당해야 한다. 하지만 물리메모리의 크기는 한계가 있기 때문에 모든 프로세스의 모든 프레임을 물리메모리에 올릴 수 없고 일부는 스왑영역에 저장된다. 문제는 멀티프로그래밍 정도가 늘어나는 경우에 나타난다. 멀티프로그래밍 정도가 늘어나면 제한된 물리메모리에 모든 프로세스를 올려야 하고 당장 실행되는 프레임을 제외한 나머지 프레임들은 스왑영역에 저장되고 page fault가 발생한다. 그러면 CPU가 작업하는 시간보다 스왑작업의 시간이 더 길어지고 CPU 사용률은 떨어진다. CPU 스케줄러는 CPU 사용률이 낮아지면 더 많은 프로세스를 메모리에 올리게 되고 이렇게 반복하면 어느 새 CPU 사용률은 0에 가깝게 된다. CPU 사용률을 높이려고 했지만 오히려 더 떨어지는 이와 같은 상황을 스레싱이라고 한다. 스레싱의 근본적인 원인은 물리메모리의 크기가 부족한 것이다. 이를 하드웨어적으로 해결하려면 메모리의 크기를 늘리면 된다. 예를 들어 2GB의 램을 사용하다가 스래싱이 발생하면 4GB의 램으로 교체해주면 스레싱 발생지점이 늦춰지기 때문에 컴퓨터의 성능이 향상된다. 하지만 무작정 메모리의 크기를 늘린다고 성능은 좋아지지 않는다. 4GB의 램에서 16GB로 올려도 성능향상을 느끼기는 힘들다. 그 이유는 현재 메모리가 프로세스들이 작업을 하는데 충분한 크기라서 스레싱이 발생하지 않는다면 크기를 늘려도 별 다른 점이 없다.

운영체제가 스레싱을 소프트웨어적으로 해결하기 위한 방법을 알아보자. 한 프로세스가 실행될 때 너무 많은 페이지를 할당하면 다른 프로세스가 사용할 페이지가 줄어들기 때문에 효율이 떨어진다. 반대로 너무 적은 페이지를 할당하면 빈번한 page fault가 발생하고 스왑요청이 많아 스레싱이 발생한다. 이를 해결하기 위해 프로세스가 실행되면 일정량의 페이지를 할당하고 만약 page fault가 발생하면 더 많은 페이지를 할당한다. 반대로 page fault가 너무 적게 발생하면 페이지를 과하게 할당해 메모리가 낭비되는 것이라고 판단하고 페이지를 회수한다. 이렇게 하면 프로세스가 실행되는 동안 해당 프로세스에게 맞는 적절한 페이지 수를 결정할 수 있다.

적절한 페이지 수를 결정했다면 어떤 페이지들을 유지할지를 알아야 한다. 이는 지역성 이론을 따른다. 현재 메모리에 올라온 페이지는 다시 사용할 확률이 높기 때문에 하나의 세트로 묶어서 메모리에 올린다. 이를 워킹셋이라고 부른다. 워킹셋은 프로세스가 준비상태에서 실행상태가 되는 컨텍스트 스위칭을 할 때 사용한다.
